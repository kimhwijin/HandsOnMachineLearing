{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HOML_Exercise_16.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1Fr4Ovc4aFGXpKVcgJ_lrNHnjtxWvrN3l",
      "authorship_tag": "ABX9TyN0YiOd4m/IHPz6gS1kW1Wu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimhwijin/HandsOnMachineLearing/blob/main/HOML_Exercise_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E8hNZpeOZvOV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "cOBH9WrNgMyU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8."
      ],
      "metadata": {
        "id": "-I_I4OsAaA8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grammer_StringGenerater"
      ],
      "metadata": {
        "id": "W3a5SCznh6zb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#문법에 맞는 문자열을 반환하는 함수\n",
        "\n",
        "#문법, LR table 과 비슷함\n",
        "default_reber_grammar = [\n",
        "    [(\"B\", 1)],           # (state 0) =B=>(state 1)\n",
        "    [(\"T\", 2), (\"P\", 3)], # (state 1) =T=>(state 2) or =P=>(state 3)\n",
        "    [(\"S\", 2), (\"X\", 4)], # (state 2) =S=>(state 2) or =X=>(state 4)\n",
        "    [(\"T\", 3), (\"V\", 5)], # and so on...\n",
        "    [(\"X\", 3), (\"S\", 6)],\n",
        "    [(\"P\", 4), (\"V\", 6)],\n",
        "    #마지막\n",
        "    [(\"E\", None)]]        # (state 6) =E=>(terminal state)\n",
        "\n",
        "embedded_reber_grammar = [\n",
        "    [(\"B\", 1)],\n",
        "    [(\"T\", 2), (\"P\", 3)],\n",
        "    [(default_reber_grammar, 4)],\n",
        "    [(default_reber_grammar, 5)],\n",
        "    [(\"T\", 6)],\n",
        "    [(\"P\", 6)],\n",
        "    #마지막\n",
        "    [(\"E\", None)]]\n",
        "\n",
        "def generate_string(grammar):\n",
        "    state = 0\n",
        "    output=[]\n",
        "    while state is not None:\n",
        "        index = np.random.randint(len(grammar[state]))\n",
        "        #다음 문자와 상태\n",
        "        production, state = grammar[state][index]\n",
        "        if isinstance(production, list):\n",
        "            production = generate_string(grammar=production)\n",
        "        output.append(production)\n",
        "    return \"\".join(output)"
      ],
      "metadata": {
        "id": "NTSOz5XNZ_Mh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(25):\n",
        "    #25개의 문자열 생성\n",
        "    print(generate_string(default_reber_grammar), end=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeL37UA2a9ss",
        "outputId": "338d0f39-dde9-4949-ae03-051e4a279d54"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BTXXTTVPXTVPXTTVPSE BPVPSE BTXSE BPVVE BPVVE BTSXSE BPTVPXTTTVVE BPVVE BTXSE BTXXVPSE BPTTTTTTTTVVE BTXSE BPVPSE BTXSE BPTVPSE BTXXTVPSE BPVVE BPVVE BPVVE BPTTVVE BPVVE BPVVE BTXXVVE BTXXVVE BTXXVPXVVE "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Wrong_StringGenrater"
      ],
      "metadata": {
        "id": "DNim0fuEiB2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모든 가능한 알파벳들\n",
        "POSSIBLE_CHARS = \"BEPSTVX\"\n",
        "\n",
        "#잘못된 문자열 만들기\n",
        "def generate_corrupted_string(grammar, chars=POSSIBLE_CHARS):\n",
        "    #올바른 문자열에\n",
        "    good_string = generate_string(grammar)\n",
        "    index = np.random.randint(len(good_string))\n",
        "    good_char = good_string[index]\n",
        "    #있을수는 있지만 올바른 문자열엔 없는 문자열을\n",
        "    bad_char = np.random.choice(sorted(set(chars) - set(good_char)))\n",
        "    #중간에 하나 추가함\n",
        "    return good_string[:index] + bad_char + good_string[index + 1:]"
      ],
      "metadata": {
        "id": "zN88lc-qbMOH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#잘못된 문자열\n",
        "for _ in range(25):\n",
        "    print(generate_corrupted_string(embedded_reber_grammar), end=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QorG2sjibidd",
        "outputId": "693d562f-4ee2-446d-ea99-050500e77935"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BTBPVVETV BTBTSSSPXXVVETE BTBTXXTTSTVPSETE BBBTXSETE BPBTPXSEPE BPBPVPXTTTTVPXTVPXVPXTTTVVEVE BTBXXXTVPSETE BEBTSSSSSXXVPXTVVETE BTBXTTVVETE BPBTXSTPE BTBTXXTTTVPSBTE BTBTXSETX BTBTSXSSTE BPBPVVEPT BTBPTVEETE BTBTSSXXTTVXETE BTBTSXTTVVETE BPBPVVTPE BTBTSXTTVVETE EPBPVPXVVEPE BPTTXSEPE BPBTXXSPXTVVEPE BTBTXSPTE BPTTSXXTVPXVVEPE PPBPVPSEPE "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Char_To_Int"
      ],
      "metadata": {
        "id": "XzIk9HnZiIEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#문자열을 숫자로 바꾸기, 문자의 인덱스 리스트로 변경한다.\n",
        "def strings_to_ids(s, chars=POSSIBLE_CHARS):\n",
        "    return [chars.index(c) for c in s]"
      ],
      "metadata": {
        "id": "PrErPKNRgirg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataGenerater"
      ],
      "metadata": {
        "id": "ZDBhm6oJiN6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#올바른 문자열, 잘못된 문자열 1 : 1 인 샘플과 레이블 생성\n",
        "def generate_dataset(size):\n",
        "    good_strings = [strings_to_ids(generate_string(embedded_reber_grammar)) for _ in range(size // 2)]\n",
        "    bad_strings = [strings_to_ids(generate_corrupted_string(embedded_reber_grammar)) for _ in range(size // 2)]\n",
        "    all_strings = good_strings + bad_strings\n",
        "    #ragged 텐서 생성\n",
        "    X = tf.ragged.constant(all_strings, ragged_rank=1)\n",
        "    y = np.array([[1.] for _ in range(len(good_strings))] + [[0.] for _ in range(len(bad_strings))])\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "wIQJCCtrb_6G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate_Data"
      ],
      "metadata": {
        "id": "HXsHV0dPiUAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = generate_dataset(10000)\n",
        "X_valid, y_valid = generate_dataset(2000)\n",
        "X_test, y_test = generate_dataset(2000)"
      ],
      "metadata": {
        "id": "MrWpQwZecAGU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])\n",
        "s = ''\n",
        "for i in X_train[0]:\n",
        "    s += POSSIBLE_CHARS[i]\n",
        "print(s, y_train[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTjH-aNsgYpK",
        "outputId": "11a43228-05e9-4455-ae5e-4e984cc0fd32"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 4 0 2 5 5 1 4 1], shape=(9,), dtype=int32)\n",
            "BTBPVVETE 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Binary_Sequence_Classifier"
      ],
      "metadata": {
        "id": "UYff-SVGiYoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 5\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    #인풋데이터는 ragged tensor, int32 타입\n",
        "    keras.layers.InputLayer(input_shape=[None], dtype=tf.int32, ragged=True),\n",
        "    keras.layers.Embedding(input_dim=len(POSSIBLE_CHARS), output_dim=embedding_size),\n",
        "    keras.layers.GRU(30),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "#네스테로프 가속 경사하강법 \n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.02, momentum=0.95, nesterov=True)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qfvhUibehqAf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model_Train"
      ],
      "metadata": {
        "id": "XxCVuMK6kxut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-tLbiqajhY8",
        "outputId": "9b1cb904-b2da-4998-bfb7-8679a50f6968"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/gru/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/gru/RaggedToTensor/boolean_mask/GatherV2:0\", shape=(None, 5), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/gru/RaggedToTensor/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 33s 92ms/step - loss: 0.6910 - accuracy: 0.5093 - val_loss: 0.6825 - val_accuracy: 0.5595\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.6678 - accuracy: 0.5720 - val_loss: 0.6706 - val_accuracy: 0.5975\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 31s 100ms/step - loss: 0.6505 - accuracy: 0.5796 - val_loss: 0.6472 - val_accuracy: 0.6135\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 31s 98ms/step - loss: 0.6356 - accuracy: 0.5963 - val_loss: 0.6239 - val_accuracy: 0.6290\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.6059 - accuracy: 0.6342 - val_loss: 0.5778 - val_accuracy: 0.7010\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.5474 - accuracy: 0.7015 - val_loss: 0.5608 - val_accuracy: 0.5500\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 31s 98ms/step - loss: 0.4107 - accuracy: 0.8141 - val_loss: 0.4382 - val_accuracy: 0.7820\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 29s 92ms/step - loss: 0.2550 - accuracy: 0.9049 - val_loss: 0.1390 - val_accuracy: 0.9590\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.1200 - accuracy: 0.9649 - val_loss: 0.0663 - val_accuracy: 0.9850\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 30s 94ms/step - loss: 0.0965 - accuracy: 0.9737 - val_loss: 0.2410 - val_accuracy: 0.9105\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 31s 98ms/step - loss: 0.1131 - accuracy: 0.9676 - val_loss: 0.0381 - val_accuracy: 0.9895\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 0.0471 - accuracy: 0.9890 - val_loss: 0.0758 - val_accuracy: 0.9710\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 30s 94ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 8.9464e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 30s 96ms/step - loss: 7.7215e-04 - accuracy: 1.0000 - val_loss: 5.9661e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 29s 93ms/step - loss: 5.5264e-04 - accuracy: 1.0000 - val_loss: 4.5413e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 30s 97ms/step - loss: 4.2233e-04 - accuracy: 1.0000 - val_loss: 3.6655e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 30s 94ms/step - loss: 3.4531e-04 - accuracy: 1.0000 - val_loss: 3.0827e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 29s 93ms/step - loss: 2.9229e-04 - accuracy: 1.0000 - val_loss: 2.6583e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 30s 95ms/step - loss: 2.5463e-04 - accuracy: 1.0000 - val_loss: 2.3538e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 30s 95ms/step - loss: 2.2494e-04 - accuracy: 1.0000 - val_loss: 2.0977e-04 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model_Evaluate"
      ],
      "metadata": {
        "id": "t--R2q2Skzwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpS4OKE8kp_I",
        "outputId": "42ec642e-29ab-461c-8341-a74bafb2e389"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1s 15ms/step - loss: 2.1198e-04 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.00021197657042648643, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9."
      ],
      "metadata": {
        "id": "akJLsnAjlwfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9-1"
      ],
      "metadata": {
        "id": "1z0AbCO79i0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random_Date_Genrater"
      ],
      "metadata": {
        "id": "_6E6EwcLoalq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "\n",
        "#January 22, 2019 -> 2019-01-22 형식으로\n",
        "MONTHS = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
        "\n",
        "def random_dates(n_dates):\n",
        "    min_date = date(1000, 1, 1).toordinal()\n",
        "    max_date = date(9999, 12, 31).toordinal()\n",
        "\n",
        "    #숫자\n",
        "    ordinals = np.random.randint(max_date - min_date, size=n_dates) + min_date\n",
        "    #month, day, year 을 빼내기위해서\n",
        "    dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
        "\n",
        "    #샘플\n",
        "    X = [MONTHS[dt.month - 1] + \" \" + dt.strftime(\"%d, %Y\") for dt in dates]\n",
        "    #타깃 YYYY-mm-dd 형식으로 변환\n",
        "    y = [dt.isoformat() for dt in dates]\n",
        "    \n",
        "    return X, y"
      ],
      "metadata": {
        "id": "v27muj8wkCaA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_dates = 3\n",
        "x_example, y_example = random_dates(n_dates)\n",
        "print(\"{:25s}{:25s}\".format(\"Input\", \"Target\"))\n",
        "print(\"-\" * 50)\n",
        "for idx in range(n_dates):\n",
        "    print(\"{:25s}{:25s}\".format(x_example[idx], y_example[idx]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeR-1Hm5oFo_",
        "outputId": "dd4950ed-fce3-481d-8741-3d4db396b641"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input                    Target                   \n",
            "--------------------------------------------------\n",
            "July 22, 1344            1344-07-22               \n",
            "March 21, 7185           7185-03-21               \n",
            "January 02, 5192         5192-01-02               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#INPUT_OUTPUT_CHARS"
      ],
      "metadata": {
        "id": "AjkPHuAct72Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_CHARS = \"\".join(sorted(set(\"\".join(MONTHS) + \"0123456789, \")))\n",
        "OUTPUT_CHARS = \"0123456789-\"\n",
        "INPUT_CHARS, OUTPUT_CHARS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP1YNS6XoZZw",
        "outputId": "0132f461-8ba0-400c-c836-e9e9ad12cce3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' ,0123456789ADFJMNOSabceghilmnoprstuvy', '0123456789-')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Input_Output_Tokenizer"
      ],
      "metadata": {
        "id": "UEhYuB4duC1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_chars = MONTHS + ['0123456789, ']\n",
        "output_chars = ['0123456789-']\n",
        "\n",
        "input_tokenizer = keras.preprocessing.text.Tokenizer(lower=False, char_level=True)\n",
        "input_tokenizer.fit_on_texts(sorted(set(input_chars)))\n",
        "input_vocab_size = len(input_tokenizer.word_index)\n",
        "\n",
        "output_tokenizer = keras.preprocessing.text.Tokenizer(lower=False, char_level=True)\n",
        "output_tokenizer.fit_on_texts(sorted(set(output_chars)))\n",
        "output_vocab_size = len(output_tokenizer.word_index)"
      ],
      "metadata": {
        "id": "OAsFfLXWo1Rp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_tokenizer.word_index)\n",
        "print(output_tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KizIjzmbqf0Q",
        "outputId": "1e0e166e-0eba-4751-d4bc-ab5049dfad1f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'e': 1, 'r': 2, 'u': 3, 'b': 4, 'a': 5, 'y': 6, 't': 7, 'c': 8, 'm': 9, 'J': 10, 'A': 11, 'p': 12, 'l': 13, 'n': 14, 'M': 15, 'o': 16, '0': 17, '1': 18, '2': 19, '3': 20, '4': 21, '5': 22, '6': 23, '7': 24, '8': 25, '9': 26, ',': 27, ' ': 28, 'i': 29, 'g': 30, 's': 31, 'D': 32, 'F': 33, 'h': 34, 'N': 35, 'v': 36, 'O': 37, 'S': 38}\n",
            "{'0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, '-': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = random_dates(3)\n",
        "\n",
        "print('-'*25)\n",
        "print(X[0])\n",
        "X = input_tokenizer.texts_to_sequences(X)\n",
        "print(X[0])\n",
        "X = input_tokenizer.sequences_to_texts(X)\n",
        "print(X[0][::2])\n",
        "\n",
        "print('-'*25)\n",
        "\n",
        "print(y[0])\n",
        "y = output_tokenizer.texts_to_sequences(y)\n",
        "print(y[0])\n",
        "y = output_tokenizer.sequences_to_texts(y)\n",
        "print(y[0][::2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGWcYoYYtO6s",
        "outputId": "71ce4155-c38e-41f2-9111-352d640f1d84"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "April 09, 3947\n",
            "[11, 12, 2, 29, 13, 28, 17, 26, 27, 28, 20, 26, 21, 24]\n",
            "April 09, 3947\n",
            "-------------------------\n",
            "3947-04-09\n",
            "[4, 10, 5, 8, 11, 1, 5, 11, 1, 10]\n",
            "3947-04-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset_Generater"
      ],
      "metadata": {
        "id": "7RPhEGkzuG--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_date_strs(date_strs, tokenizer):\n",
        "    ids = [dt for dt in tokenizer.texts_to_sequences(date_strs)]\n",
        "    X = tf.ragged.constant(ids, ragged_rank=1)\n",
        "    return X.to_tensor() #ragged 텐서를 기본 텐서로 부족한 부분은 0 패딩토큰으로 채운다.\n",
        "\n",
        "def create_dataset(n_dates):\n",
        "    X, Y = random_dates(n_dates)\n",
        "    return prepare_date_strs(X, input_tokenizer), prepare_date_strs(Y, output_tokenizer)"
      ],
      "metadata": {
        "id": "mZ2Zw8YKp2gs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = create_dataset(10000)\n",
        "X_valid, Y_valid = create_dataset(2000)\n",
        "X_test, Y_test = create_dataset(2000)"
      ],
      "metadata": {
        "id": "jPvrYD8DtDxW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0], Y_train[0], sep='\\n')\n",
        "print(input_tokenizer.sequences_to_texts([X_train[0].numpy()])[0][::2])\n",
        "print(output_tokenizer.sequences_to_texts([Y_train[0].numpy()])[0][::2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGavgDWOtExG",
        "outputId": "2173e850-5922-46f6-cc85-cc3720ae7158"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([15  5  6 28 17 22 27 28 22 24 18 24  0  0  0  0  0  0], shape=(18,), dtype=int32)\n",
            "tf.Tensor([ 6  8  2  8 11  1  6 11  1  6], shape=(10,), dtype=int32)\n",
            "May 05, 5717\n",
            "5717-05-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Seq2Seq_Model"
      ],
      "metadata": {
        "id": "wdc1-KQzuLO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 32\n",
        "#출력 최대 길이 : 10 (yyyy-mm-dd)\n",
        "max_output_length = Y_train.shape[-1]\n",
        "\n",
        "#인코더 디코더 구조를 사용한다.\n",
        "\n",
        "#인코더, 시퀀스 투 벡터 구조\n",
        "encoder = keras.models.Sequential([\n",
        "    keras.layers.Embedding(input_dim=input_vocab_size + 1, output_dim=embedding_size, input_shape=[None]),\n",
        "    keras.layers.LSTM(128)\n",
        "])\n",
        "\n",
        "decoder = keras.models.Sequential([\n",
        "    keras.layers.LSTM(128, return_sequences=True),\n",
        "    keras.layers.Dense(output_vocab_size + 1, activation='softmax')\n",
        "])\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    encoder,\n",
        "    #출력길이가 10이니깐 인코더 출력을 10번 반복해서, 디코더가 10개의 출력을 만들도록함\n",
        "    keras.layers.RepeatVector(max_output_length),\n",
        "    decoder\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u3NUSFrtE2-",
        "outputId": "b3b94fd6-5a31-4df9-9717-a64c260eb4d6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_1 (Sequential)   (None, 128)               83680     \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 10, 128)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " sequential_2 (Sequential)   (None, 10, 12)            133132    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 216,812\n",
            "Trainable params: 216,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Nadam()\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yVNDBUquyezt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aic4qNg5ysUY",
        "outputId": "f47199ad-d26b-47d5-8927-72df6f778b85"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 11s 15ms/step - loss: 1.8123 - accuracy: 0.3460 - val_loss: 1.4039 - val_accuracy: 0.4805\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 1.2734 - accuracy: 0.5424 - val_loss: 1.0721 - val_accuracy: 0.6217\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.9944 - accuracy: 0.6487 - val_loss: 0.8298 - val_accuracy: 0.7014\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.7202 - accuracy: 0.7332 - val_loss: 0.6222 - val_accuracy: 0.7632\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.7677 - accuracy: 0.7216 - val_loss: 0.5274 - val_accuracy: 0.7948\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.5844 - accuracy: 0.7871 - val_loss: 0.4153 - val_accuracy: 0.8364\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.3369 - accuracy: 0.8690 - val_loss: 0.2816 - val_accuracy: 0.8903\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2307 - accuracy: 0.9194 - val_loss: 0.1790 - val_accuracy: 0.9433\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.1476 - accuracy: 0.9599 - val_loss: 0.1028 - val_accuracy: 0.9771\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0717 - accuracy: 0.9864 - val_loss: 0.0561 - val_accuracy: 0.9901\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0393 - accuracy: 0.9950 - val_loss: 0.0329 - val_accuracy: 0.9950\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.1596 - accuracy: 0.9652 - val_loss: 0.0424 - val_accuracy: 0.9955\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 5s 14ms/step - loss: 0.0264 - accuracy: 0.9983 - val_loss: 0.0216 - val_accuracy: 0.9977\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.0150 - accuracy: 0.9995 - val_loss: 0.0144 - val_accuracy: 0.9990\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0101 - accuracy: 0.9998 - val_loss: 0.0105 - val_accuracy: 0.9992\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0071 - accuracy: 0.9999 - val_loss: 0.0078 - val_accuracy: 0.9994\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9997\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9999\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vDkzHXF4UDN",
        "outputId": "3c763fa7-6e2d-467c-cdc6-0cf3df4fcc36"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0027159270830452442, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model_Return_To_Strings"
      ],
      "metadata": {
        "id": "U-kh3b2j4wwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ids_to_strings(ids, tokenizer):\n",
        "    return tokenizer.sequences_to_texts(ids)\n",
        "\n",
        "print('-'*25)\n",
        "#X_new = X_test[:3]\n",
        "#패딩이 없는 데이터셋이라 잘 예측을 못함\n",
        "X_new = prepare_date_strs([\"May 02, 2020\", \"July 14, 1789\"], input_tokenizer)\n",
        "X_samples = ids_to_strings(X_new.numpy(), input_tokenizer)\n",
        "print(*[x_sample[::2] for x_sample in X_samples], sep='\\n')\n",
        "\n",
        "\n",
        "print('-'*25)\n",
        "Y_new = np.argmax(model.predict(X_new), axis=-1)\n",
        "Y_new = ids_to_strings(Y_new, output_tokenizer)\n",
        "print(*[y_sample[::2] for y_sample in Y_new], sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCAewYw44wTh",
        "outputId": "d7297eb2-f4b5-4f29-c116-e772c4ce31e5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "May 02, 2020\n",
            "July 14, 1789\n",
            "-------------------------\n",
            "2020-02-02\n",
            "1789-09-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = X_train.shape[1]\n",
        "\n",
        "def prepare_date_strs_with_padded(date_strs, tokenizer):\n",
        "    X = prepare_date_strs(date_strs, tokenizer)\n",
        "    if X.shape[1] < max_input_length:\n",
        "        X = tf.pad(X, paddings=[[0,0], [0, max_input_length - X.shape[1]]])\n",
        "    return X\n",
        "\n",
        "\n",
        "print('-'*25)\n",
        "#패딩추가, 잘예측함\n",
        "X_new = prepare_date_strs_with_padded([\"May 02, 2020\", \"July 14, 1789\"], input_tokenizer)\n",
        "X_samples = ids_to_strings(X_new.numpy(), input_tokenizer)\n",
        "print(*[x_sample[::2] for x_sample in X_samples], sep='\\n')\n",
        "\n",
        "\n",
        "print('-'*25)\n",
        "Y_new = np.argmax(model.predict(X_new), axis=-1)\n",
        "Y_new = ids_to_strings(Y_new, output_tokenizer)\n",
        "print(*[y_sample[::2] for y_sample in Y_new], sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epYHWsGi79k0",
        "outputId": "c6b1b0a0-0aef-44e5-d0b6-d95aa43d9a42"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "May 02, 2020\n",
            "July 14, 1789\n",
            "-------------------------\n",
            "2020-05-02\n",
            "1789-07-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9-2"
      ],
      "metadata": {
        "id": "rVtUzeUm9l6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decoder_Input_Target_Shift"
      ],
      "metadata": {
        "id": "codkA4LE-68c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sos_id = output_vocab_size + 1\n",
        "\n",
        "def shifted_output_sequences(Y):\n",
        "    sos_tokens = tf.fill(dims=(len(Y), 1), value=sos_id)\n",
        "    return tf.concat([sos_tokens, Y[:, :-1]], axis=1)\n",
        "\n",
        "#타깃을 오른쪽으로 한번 shift 하고 맨앞에 sos 토큰을 추가한 디코더 입력\n",
        "#원래는 인코더벡터를 복사해서 디코더에 입력했지만, 쉬프트된 타깃을 주입해서 이전타깃이 무엇인지 확인할수 있게한다.\n",
        "X_train_decoder = shifted_output_sequences(Y_train)\n",
        "X_valid_decoder = shifted_output_sequences(Y_valid)\n",
        "X_test_decoder = shifted_output_sequences(Y_test)"
      ],
      "metadata": {
        "id": "A_4wMFqR9nVj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids_to_strings(X_train_decoder[:5].numpy(), output_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX978r__-kld",
        "outputId": "705b94ce-017d-4683-c385-447f42f8eed0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['5 7 1 7 - 0 5 - 0',\n",
              " '3 7 6 2 - 0 6 - 1',\n",
              " '6 5 6 2 - 1 2 - 0',\n",
              " '3 9 8 7 - 0 3 - 0',\n",
              " '4 8 3 0 - 0 6 - 0']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "0hp8YMJC_BC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_embedding_size = 32\n",
        "decoder_embedding_size = 32\n",
        "\n",
        "lstm_units = 128\n",
        "\n",
        "encoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
        "encoder_embedding = keras.layers.Embedding(input_dim=input_vocab_size+1, output_dim=encoder_embedding_size)(encoder_input)\n",
        "#인코더의 출력벡터는 무시한다!!\n",
        "_, encoder_state_h, encoder_state_c = keras.layers.LSTM(lstm_units, return_state=True)(encoder_embedding)\n",
        "encoder_state = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "decoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
        "decoder_embedding = keras.layers.Embedding(output_vocab_size+1, decoder_embedding_size)(decoder_input)\n",
        "#대신 인코더의 LSTM의 상태와 디코더의 LSTM과 연결시킨다.\n",
        "decoder_lstm_output = keras.layers.LSTM(lstm_units, return_sequences=True)(decoder_embedding, initial_state=encoder_state)\n",
        "decoder_output = keras.layers.Dense(output_vocab_size+1, activation='softmax')(decoder_lstm_output)\n",
        "\n",
        "model = keras.models.Model(inputs=[encoder_input, decoder_input], outputs=[decoder_output])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7ZvSRmn-2XW",
        "outputId": "e8421795-f8a0-43fb-9653-6cd33ac8e4e8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, None, 32)     1248        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 32)     384         ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 128),        82432       ['embedding_2[0][0]']            \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, None, 128)    82432       ['embedding_3[0][0]',            \n",
            "                                                                  'lstm_2[0][1]',                 \n",
            "                                                                  'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, None, 12)     1548        ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 168,044\n",
            "Trainable params: 168,044\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([X_train, X_train_decoder], Y_train, epochs=10, validation_data=([X_valid, X_valid_decoder], Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_HI_KKmAwLO",
        "outputId": "d242d362-71cc-4600-d792-9354685d5e0c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 9s 16ms/step - loss: 1.6702 - accuracy: 0.3712 - val_loss: 1.4184 - val_accuracy: 0.4505\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 1.2336 - accuracy: 0.5262 - val_loss: 0.9797 - val_accuracy: 0.6413\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.6811 - accuracy: 0.7581 - val_loss: 0.4135 - val_accuracy: 0.8705\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.2387 - accuracy: 0.9428 - val_loss: 0.1191 - val_accuracy: 0.9822\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.0761 - accuracy: 0.9923 - val_loss: 0.0491 - val_accuracy: 0.9969\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.0680 - accuracy: 0.9901 - val_loss: 0.0258 - val_accuracy: 0.9994\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0408 - accuracy: 0.9946 - val_loss: 0.0202 - val_accuracy: 0.9994\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 4s 13ms/step - loss: 0.0133 - accuracy: 0.9999 - val_loss: 0.0107 - val_accuracy: 0.9999\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 4s 14ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9999\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ids_to_strings(np.argmax(model.predict([X_train[:5], X_train_decoder[:5]]), axis=-1), output_tokenizer))\n",
        "print(ids_to_strings(Y_train[:5].numpy(), output_tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxR3yt-2HEWs",
        "outputId": "fb2e48a1-98ed-4c40-c5a4-e46c73aa13f9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['5 7 1 7 - 0 5 - 0 5', '3 7 6 2 - 0 6 - 1 3', '6 5 6 2 - 1 2 - 0 1', '3 9 8 7 - 0 3 - 0 4', '4 8 3 0 - 0 6 - 0 5']\n",
            "['5 7 1 7 - 0 5 - 0 5', '3 7 6 2 - 0 6 - 1 3', '6 5 6 2 - 1 2 - 0 1', '3 9 8 7 - 0 3 - 0 4', '4 8 3 0 - 0 6 - 0 5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_new = output_tokenizer.texts_to_sequences([\"1789-07-14\", \"2020-05-01\"])\n",
        "\n",
        "def predict_date_strs(date_strs):\n",
        "    X = prepare_date_strs_with_padded(date_strs, input_tokenizer)\n",
        "    #X = date_strs\n",
        "    sos_id = output_vocab_size + 1\n",
        "    Y_pred = tf.fill(dims=(len(X), 1), value=sos_id)\n",
        "\n",
        "    for index in range(max_output_length):\n",
        "        X_decoder = tf.pad(Y_pred, [[0, 0], [0, max_output_length-index]])\n",
        "        Y_probas = tf.argmax(model.predict([X, X_decoder]), axis=-1, output_type=tf.int32)\n",
        "        Y_pred = tf.concat([Y_pred, Y_probas[:, index:index+1]], axis=1)\n",
        "    return ids_to_strings(Y_pred.numpy(), output_tokenizer)\n",
        "\n",
        "print(predict_date_strs([\"May 02, 2020\", \"July 14, 1789\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql1g0m9DHtk0",
        "outputId": "eb800d91-da89-4944-9d17-c7b56bace5d9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2 0 2 0 - 0 5 - 0 2', '1 7 8 9 - 0 7 - 1 4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9-3"
      ],
      "metadata": {
        "id": "O_tKelyG7zMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Addon_Sampler_Model"
      ],
      "metadata": {
        "id": "70us6ztfFHxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WoVfQq7BLAd",
        "outputId": "84695a69-c2d8-42ea-a217-75bce9cea1f5"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 14.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 12.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 12.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 12.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 12.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 12.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_addons as tfa\n",
        "\n",
        "encoder_embedding_size = 32\n",
        "decoder_embedding_size = 32\n",
        "\n",
        "units = 128\n",
        "\n",
        "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
        "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
        "\n",
        "encoder_embeddings = keras.layers.Embedding(input_vocab_size + 1, encoder_embedding_size)(encoder_inputs)\n",
        "\n",
        "encoder = keras.layers.LSTM(units, return_state=True)\n",
        "encoder_output, state_h, state_c = encoder(encoder_embeddings)\n",
        "encoder_state = [state_h, state_c]\n",
        "\n",
        "\n",
        "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
        "\n",
        "decoder_embedding_layer = keras.layers.Embedding(output_vocab_size + 2, decoder_embedding_size)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "#sampler\n",
        "sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "\n",
        "decoder_cell = keras.layers.LSTMCell(units)\n",
        "output_layer = keras.layers.Dense(output_vocab_size+1)\n",
        "\n",
        "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler, output_layer=output_layer)\n",
        "\n",
        "final_output, final_state, final_sequence_lengths = decoder(decoder_embeddings, initial_state=encoder_state)\n",
        "Y_proba = keras.layers.Activation('softmax')(final_output.rnn_output)\n",
        "\n",
        "model = keras.models.Model(inputs=[encoder_inputs, decoder_inputs], outputs=[Y_proba])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Zb0E2Sdb70ZD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([X_train, X_train_decoder], Y_train, epochs=9, validation_data=([X_valid, X_valid_decoder], Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LegU0AxjBJsv",
        "outputId": "4705f75d-f1a0-4377-a173-152b44b40252"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "313/313 [==============================] - 23s 60ms/step - loss: 1.6922 - accuracy: 0.3606 - val_loss: 1.4389 - val_accuracy: 0.4472\n",
            "Epoch 2/15\n",
            "313/313 [==============================] - 18s 59ms/step - loss: 1.2261 - accuracy: 0.5346 - val_loss: 0.9129 - val_accuracy: 0.6691\n",
            "Epoch 3/15\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 0.6279 - accuracy: 0.7817 - val_loss: 0.3537 - val_accuracy: 0.8938\n",
            "Epoch 4/15\n",
            "313/313 [==============================] - 18s 58ms/step - loss: 0.2086 - accuracy: 0.9526 - val_loss: 0.0977 - val_accuracy: 0.9894\n",
            "Epoch 5/15\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 0.0657 - accuracy: 0.9941 - val_loss: 0.0384 - val_accuracy: 0.9987\n",
            "Epoch 6/15\n",
            "313/313 [==============================] - 18s 58ms/step - loss: 0.0725 - accuracy: 0.9864 - val_loss: 0.1427 - val_accuracy: 0.9684\n",
            "Epoch 7/15\n",
            "313/313 [==============================] - 17s 54ms/step - loss: 0.0301 - accuracy: 0.9983 - val_loss: 0.0161 - val_accuracy: 0.9998\n",
            "Epoch 8/15\n",
            "313/313 [==============================] - 18s 56ms/step - loss: 0.0116 - accuracy: 0.9999 - val_loss: 0.0097 - val_accuracy: 0.9999\n",
            "Epoch 9/15\n",
            "313/313 [==============================] - 17s 54ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9999\n",
            "Epoch 10/15\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9999\n",
            "Epoch 11/15\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "313/313 [==============================] - 17s 54ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "313/313 [==============================] - 18s 56ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "313/313 [==============================] - 18s 56ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "313/313 [==============================] - 17s 53ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_date_strs([\"May 02, 2020\", \"July 14, 1789\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDEEg6iVC1OJ",
        "outputId": "e62101ed-0ed5-454b-9fbb-a4c68f16fc78"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2 0 2 0 - 0 5 - 0 2', '1 7 8 9 - 0 7 - 1 4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GreedyEmbeddingSampler"
      ],
      "metadata": {
        "id": "XhyzO3P0FF7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_sampler = tfa.seq2seq.sampler.GreedyEmbeddingSampler(embedding_fn=decoder_embedding_layer)\n",
        "\n",
        "inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, inference_sampler, output_layer=output_layer, maximum_iterations=max_output_length)\n",
        "batch_size = tf.shape(encoder_inputs)[:1]\n",
        "start_tokens = tf.fill(dims=batch_size, value=sos_id)\n",
        "final_outputs, final_state, final_sequence_lengths = inference_decoder(start_tokens, initial_state=encoder_state, start_tokens=start_tokens, end_token=0)\n",
        "\n",
        "inference_model = keras.models.Model(inputs=[encoder_inputs], outputs=[final_outputs.sample_id])"
      ],
      "metadata": {
        "id": "q6pXkCJEHQRy"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fast_predict_date_strs(date_strs):\n",
        "    X = prepare_date_strs_with_padded(date_strs, input_tokenizer)\n",
        "    Y_pred = inference_model.predict(X)\n",
        "    return ids_to_strings(Y_pred, output_tokenizer)"
      ],
      "metadata": {
        "id": "sCRLYyTrHjei"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "886WbTvKIGF1",
        "outputId": "bf43aee5-28e8-4f2d-eba6-03812c7c5371"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 633 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit fast_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS84z05UILLZ",
        "outputId": "f9281193-8d3d-4cc4-8a2b-62c72cbdea46"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 68.1 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9-4"
      ],
      "metadata": {
        "id": "Yel4zMzBJjft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Schedule_Model"
      ],
      "metadata": {
        "id": "I8ONihUwLTiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 20\n",
        "encoder_embedding_size = 32\n",
        "decoder_embedding_size = 32\n",
        "units = 128\n",
        "\n",
        "#encoder\n",
        "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
        "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
        "\n",
        "encoder_embeddings = keras.layers.Embedding(input_vocab_size + 1, encoder_embedding_size)(encoder_inputs)\n",
        "\n",
        "encoder = keras.layers.LSTM(units, return_state=True)\n",
        "encoder_output, state_h, state_c = encoder(encoder_embeddings)\n",
        "encoder_state = [state_h, state_c]\n",
        "\n",
        "#decoder\n",
        "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\\\n",
        "\n",
        "decoder_embedding_layer = keras.layers.Embedding(output_vocab_size + 2, decoder_embedding_size)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "#sampler\n",
        "#훈련할때 점진적으로 타깃에서 예측한 값을 입력으로 보낸다.\n",
        "sampler = tfa.seq2seq.sampler.ScheduledEmbeddingTrainingSampler(sampling_probability=0., embedding_fn=decoder_embedding_layer)\n",
        "sampler.sampling_probability = tf.Variable(0.)\n",
        "\n",
        "decoder_cell = keras.layers.LSTMCell(units)\n",
        "output_layer = keras.layers.Dense(output_vocab_size+1)\n",
        "\n",
        "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler, output_layer=output_layer)\n",
        "\n",
        "final_output, final_state, final_sequence_lengths = decoder(decoder_embeddings, initial_state=encoder_state)\n",
        "Y_proba = keras.layers.Activation('softmax')(final_output.rnn_output)\n",
        "\n",
        "optimizer = keras.optimizers.Nadam()\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "vOrjxr1jJlGh"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Schedule_Sampling_Probability_Callback"
      ],
      "metadata": {
        "id": "BP1TUkC4LObY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#매 에폭이 끝날때마다 예측한 값을 입력으로 보낼 확률을 올려줌\n",
        "def update_sampling_probability(epoch, logs):\n",
        "    proba = min(1.0, epoch / (n_epochs - 10))\n",
        "    sampler.sampling_probability.assign(proba)\n",
        "\n",
        "sampling_probability_cb = keras.callbacks.LambdaCallback(on_epoch_begin=update_sampling_probability)"
      ],
      "metadata": {
        "id": "CYzNqEi3KrUS"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([X_train, X_train_decoder], Y_train, epochs=n_epochs, \n",
        "                    validation_data=([X_valid, X_valid_decoder], Y_valid), \n",
        "                    callbacks=[sampling_probability_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upq7F_zBK28w",
        "outputId": "5e290f13-605a-417d-94e9-0ba37343d34e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 22s 55ms/step - loss: 0.0666 - accuracy: 0.9853 - val_loss: 0.1372 - val_accuracy: 0.9571\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 17s 53ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 8.2835e-04 - accuracy: 1.0000 - val_loss: 9.2663e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 18s 56ms/step - loss: 6.6560e-04 - accuracy: 1.0000 - val_loss: 7.6463e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 17s 53ms/step - loss: 5.5028e-04 - accuracy: 1.0000 - val_loss: 6.3837e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 4.6166e-04 - accuracy: 1.0000 - val_loss: 5.3704e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 3.9098e-04 - accuracy: 1.0000 - val_loss: 4.6374e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 17s 56ms/step - loss: 3.3286e-04 - accuracy: 1.0000 - val_loss: 4.0794e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 17s 54ms/step - loss: 2.8494e-04 - accuracy: 1.0000 - val_loss: 3.4639e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 18s 59ms/step - loss: 2.4404e-04 - accuracy: 1.0000 - val_loss: 2.9873e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 2.0910e-04 - accuracy: 1.0000 - val_loss: 2.5590e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 1.7940e-04 - accuracy: 1.0000 - val_loss: 2.1880e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 18s 57ms/step - loss: 1.5382e-04 - accuracy: 1.0000 - val_loss: 1.8864e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 18s 59ms/step - loss: 1.3175e-04 - accuracy: 1.0000 - val_loss: 1.6296e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 17s 54ms/step - loss: 1.1327e-04 - accuracy: 1.0000 - val_loss: 1.4142e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 9.6578e-05 - accuracy: 1.0000 - val_loss: 1.2035e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 17s 53ms/step - loss: 8.2647e-05 - accuracy: 1.0000 - val_loss: 1.0481e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 7.0411e-05 - accuracy: 1.0000 - val_loss: 8.9888e-05 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference_SampleEmbeddingSampler"
      ],
      "metadata": {
        "id": "a8mUMDlPL1TJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_temperature = tf.Variable(1.)\n",
        "\n",
        "inference_sampler = tfa.seq2seq.sampler.SampleEmbeddingSampler(embedding_fn=decoder_embedding_layer, softmax_temperature=softmax_temperature)\n",
        "inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, inference_sampler, output_layer=output_layer, maximum_iterations=max_output_length)\n",
        "\n",
        "batch_size = tf.shape(encoder_inputs)[:1]\n",
        "start_tokens = tf.fill(dims=batch_size, value=sos_id)\n",
        "\n",
        "final_outputs, final_state, final_sequence_lengths = inference_decoder(start_tokens, initial_state=encoder_state, start_tokens=start_tokens, end_token=0)\n",
        "\n",
        "inference_model = keras.models.Model(inputs=[encoder_inputs], outputs=[final_outputs.sample_id])"
      ],
      "metadata": {
        "id": "hZ9l0idCL0rq"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def creative_predict_date_strs(date_strs, temperature=1.0):\n",
        "    softmax_temperature.assign(temperature)\n",
        "    X = prepare_date_strs_with_padded(date_strs, input_tokenizer)\n",
        "    Y_pred = inference_model.predict(X)\n",
        "    return ids_to_strings(Y_pred, output_tokenizer)\n",
        "\n",
        "print(creative_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"]))\n",
        "print(creative_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"], 5.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLa2btjIMDtT",
        "outputId": "6a400f61-ffbb-442f-f496-ae3beb82a305"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['9 4 6 4 5 1 7 8 1 -', '9 3 8 9 7 3 2 5 7 7']\n",
            "['6 6 6 - 0 1 4 - - 2', '4 6 9 3 3 4 1 - 9 0']\n"
          ]
        }
      ]
    }
  ]
}