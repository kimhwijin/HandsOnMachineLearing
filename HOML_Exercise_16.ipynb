{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HOML_Exercise_16.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "t--R2q2Skzwh",
        "akJLsnAjlwfR",
        "1z0AbCO79i0F",
        "rVtUzeUm9l6q",
        "O_tKelyG7zMc",
        "Yel4zMzBJjft",
        "atNGcKddjGCR"
      ],
      "mount_file_id": "1Fr4Ovc4aFGXpKVcgJ_lrNHnjtxWvrN3l",
      "authorship_tag": "ABX9TyN1sX+9lk+njuOEQ7G7vK0/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimhwijin/HandsOnMachineLearing/blob/main/HOML_Exercise_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "id": "wZFO65xLJ9j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "E8hNZpeOZvOV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "cOBH9WrNgMyU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8."
      ],
      "metadata": {
        "id": "-I_I4OsAaA8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grammer_StringGenerater"
      ],
      "metadata": {
        "id": "W3a5SCznh6zb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#문법에 맞는 문자열을 반환하는 함수\n",
        "\n",
        "#문법, LR table 과 비슷함\n",
        "default_reber_grammar = [\n",
        "    [(\"B\", 1)],           # (state 0) =B=>(state 1)\n",
        "    [(\"T\", 2), (\"P\", 3)], # (state 1) =T=>(state 2) or =P=>(state 3)\n",
        "    [(\"S\", 2), (\"X\", 4)], # (state 2) =S=>(state 2) or =X=>(state 4)\n",
        "    [(\"T\", 3), (\"V\", 5)], # and so on...\n",
        "    [(\"X\", 3), (\"S\", 6)],\n",
        "    [(\"P\", 4), (\"V\", 6)],\n",
        "    #마지막\n",
        "    [(\"E\", None)]]        # (state 6) =E=>(terminal state)\n",
        "\n",
        "embedded_reber_grammar = [\n",
        "    [(\"B\", 1)],\n",
        "    [(\"T\", 2), (\"P\", 3)],\n",
        "    [(default_reber_grammar, 4)],\n",
        "    [(default_reber_grammar, 5)],\n",
        "    [(\"T\", 6)],\n",
        "    [(\"P\", 6)],\n",
        "    #마지막\n",
        "    [(\"E\", None)]]\n",
        "\n",
        "def generate_string(grammar):\n",
        "    state = 0\n",
        "    output=[]\n",
        "    while state is not None:\n",
        "        index = np.random.randint(len(grammar[state]))\n",
        "        #다음 문자와 상태\n",
        "        production, state = grammar[state][index]\n",
        "        if isinstance(production, list):\n",
        "            production = generate_string(grammar=production)\n",
        "        output.append(production)\n",
        "    return \"\".join(output)"
      ],
      "metadata": {
        "id": "NTSOz5XNZ_Mh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(25):\n",
        "    #25개의 문자열 생성\n",
        "    print(generate_string(default_reber_grammar), end=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeL37UA2a9ss",
        "outputId": "79a230c1-7091-4313-d9a4-adf67d560d6c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BTXXTTVPXTVPXTTVPSE BPVPSE BTXSE BPVVE BPVVE BTSXSE BPTVPXTTTVVE BPVVE BTXSE BTXXVPSE BPTTTTTTTTVVE BTXSE BPVPSE BTXSE BPTVPSE BTXXTVPSE BPVVE BPVVE BPVVE BPTTVVE BPVVE BPVVE BTXXVVE BTXXVVE BTXXVPXVVE "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Wrong_StringGenrater"
      ],
      "metadata": {
        "id": "DNim0fuEiB2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모든 가능한 알파벳들\n",
        "POSSIBLE_CHARS = \"BEPSTVX\"\n",
        "\n",
        "#잘못된 문자열 만들기\n",
        "def generate_corrupted_string(grammar, chars=POSSIBLE_CHARS):\n",
        "    #올바른 문자열에\n",
        "    good_string = generate_string(grammar)\n",
        "    index = np.random.randint(len(good_string))\n",
        "    good_char = good_string[index]\n",
        "    #있을수는 있지만 올바른 문자열엔 없는 문자열을\n",
        "    bad_char = np.random.choice(sorted(set(chars) - set(good_char)))\n",
        "    #중간에 하나 추가함\n",
        "    return good_string[:index] + bad_char + good_string[index + 1:]"
      ],
      "metadata": {
        "id": "zN88lc-qbMOH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#잘못된 문자열\n",
        "for _ in range(25):\n",
        "    print(generate_corrupted_string(embedded_reber_grammar), end=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QorG2sjibidd",
        "outputId": "b4374b9b-ab88-47b4-d855-1d636f83336a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BTBPVVETV BTBTSSSPXXVVETE BTBTXXTTSTVPSETE BBBTXSETE BPBTPXSEPE BPBPVPXTTTTVPXTVPXVPXTTTVVEVE BTBXXXTVPSETE BEBTSSSSSXXVPXTVVETE BTBXTTVVETE BPBTXSTPE BTBTXXTTTVPSBTE BTBTXSETX BTBTSXSSTE BPBPVVEPT BTBPTVEETE BTBTSSXXTTVXETE BTBTSXTTVVETE BPBPVVTPE BTBTSXTTVVETE EPBPVPXVVEPE BPTTXSEPE BPBTXXSPXTVVEPE BTBTXSPTE BPTTSXXTVPXVVEPE PPBPVPSEPE "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Char_To_Int"
      ],
      "metadata": {
        "id": "XzIk9HnZiIEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#문자열을 숫자로 바꾸기, 문자의 인덱스 리스트로 변경한다.\n",
        "def strings_to_ids(s, chars=POSSIBLE_CHARS):\n",
        "    return [chars.index(c) for c in s]"
      ],
      "metadata": {
        "id": "PrErPKNRgirg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataGenerater"
      ],
      "metadata": {
        "id": "ZDBhm6oJiN6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#올바른 문자열, 잘못된 문자열 1 : 1 인 샘플과 레이블 생성\n",
        "def generate_dataset(size):\n",
        "    good_strings = [strings_to_ids(generate_string(embedded_reber_grammar)) for _ in range(size // 2)]\n",
        "    bad_strings = [strings_to_ids(generate_corrupted_string(embedded_reber_grammar)) for _ in range(size // 2)]\n",
        "    all_strings = good_strings + bad_strings\n",
        "    #ragged 텐서 생성\n",
        "    X = tf.ragged.constant(all_strings, ragged_rank=1)\n",
        "    y = np.array([[1.] for _ in range(len(good_strings))] + [[0.] for _ in range(len(bad_strings))])\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "wIQJCCtrb_6G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate_Data"
      ],
      "metadata": {
        "id": "HXsHV0dPiUAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = generate_dataset(10000)\n",
        "X_valid, y_valid = generate_dataset(2000)\n",
        "X_test, y_test = generate_dataset(2000)"
      ],
      "metadata": {
        "id": "MrWpQwZecAGU"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])\n",
        "s = ''\n",
        "for i in X_train[0]:\n",
        "    s += POSSIBLE_CHARS[i]\n",
        "print(s, y_train[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTjH-aNsgYpK",
        "outputId": "cb30c573-3b7a-4eb6-f2c5-ada50a9e837c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 4 0 2 5 5 1 4 1], shape=(9,), dtype=int32)\n",
            "BTBPVVETE 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Binary_Sequence_Classifier"
      ],
      "metadata": {
        "id": "UYff-SVGiYoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 5\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    #인풋데이터는 ragged tensor, int32 타입\n",
        "    keras.layers.InputLayer(input_shape=[None], dtype=tf.int32, ragged=True),\n",
        "    keras.layers.Embedding(input_dim=len(POSSIBLE_CHARS), output_dim=embedding_size),\n",
        "    keras.layers.GRU(30),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "#네스테로프 가속 경사하강법 \n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.02, momentum=0.95, nesterov=True)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qfvhUibehqAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model_Train"
      ],
      "metadata": {
        "id": "XxCVuMK6kxut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-tLbiqajhY8",
        "outputId": "73324637-d686-4519-8c19-c12c4e20913a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/gru/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/gru/RaggedToTensor/boolean_mask/GatherV2:0\", shape=(None, 5), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/gru/RaggedToTensor/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 20s 55ms/step - loss: 0.6910 - accuracy: 0.5093 - val_loss: 0.6825 - val_accuracy: 0.5595\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 0.6678 - accuracy: 0.5720 - val_loss: 0.6706 - val_accuracy: 0.5975\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 0.6505 - accuracy: 0.5796 - val_loss: 0.6472 - val_accuracy: 0.6135\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 17s 56ms/step - loss: 0.6356 - accuracy: 0.5963 - val_loss: 0.6239 - val_accuracy: 0.6290\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 18s 56ms/step - loss: 0.6059 - accuracy: 0.6342 - val_loss: 0.5778 - val_accuracy: 0.7010\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 17s 56ms/step - loss: 0.5474 - accuracy: 0.7015 - val_loss: 0.5608 - val_accuracy: 0.5500\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 0.3947 - accuracy: 0.8246 - val_loss: 0.2995 - val_accuracy: 0.8870\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 0.4298 - accuracy: 0.8124 - val_loss: 0.4701 - val_accuracy: 0.7770\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 17s 54ms/step - loss: 0.3047 - accuracy: 0.8829 - val_loss: 0.2917 - val_accuracy: 0.8905\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 0.1288 - accuracy: 0.9661 - val_loss: 0.0894 - val_accuracy: 0.9785\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 0.0828 - accuracy: 0.9803 - val_loss: 0.0790 - val_accuracy: 0.9795\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 0.0720 - accuracy: 0.9825 - val_loss: 0.0728 - val_accuracy: 0.9815\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 0.0490 - accuracy: 0.9882 - val_loss: 0.0121 - val_accuracy: 0.9965\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 0.0085 - accuracy: 0.9987 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 18s 56ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 18s 56ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 18s 57ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 8.7813e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 17s 55ms/step - loss: 8.8223e-04 - accuracy: 1.0000 - val_loss: 7.7920e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 17s 54ms/step - loss: 7.4183e-04 - accuracy: 1.0000 - val_loss: 6.4329e-04 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model_Evaluate"
      ],
      "metadata": {
        "id": "t--R2q2Skzwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpS4OKE8kp_I",
        "outputId": "d4b793ef-72e8-4f76-bd54-ee467d52c2c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1s 9ms/step - loss: 6.7382e-04 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0006738215452060103, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9."
      ],
      "metadata": {
        "id": "akJLsnAjlwfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9-1"
      ],
      "metadata": {
        "id": "1z0AbCO79i0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random_Date_Genrater"
      ],
      "metadata": {
        "id": "_6E6EwcLoalq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "\n",
        "#January 22, 2019 -> 2019-01-22 형식으로\n",
        "MONTHS = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
        "\n",
        "def random_dates(n_dates):\n",
        "    min_date = date(1000, 1, 1).toordinal()\n",
        "    max_date = date(9999, 12, 31).toordinal()\n",
        "\n",
        "    #숫자\n",
        "    ordinals = np.random.randint(max_date - min_date, size=n_dates) + min_date\n",
        "    #month, day, year 을 빼내기위해서\n",
        "    dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
        "\n",
        "    #샘플\n",
        "    X = [MONTHS[dt.month - 1] + \" \" + dt.strftime(\"%d, %Y\") for dt in dates]\n",
        "    #타깃 YYYY-mm-dd 형식으로 변환\n",
        "    y = [dt.isoformat() for dt in dates]\n",
        "    \n",
        "    return X, y"
      ],
      "metadata": {
        "id": "v27muj8wkCaA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_dates = 3\n",
        "x_example, y_example = random_dates(n_dates)\n",
        "print(\"{:25s}{:25s}\".format(\"Input\", \"Target\"))\n",
        "print(\"-\" * 50)\n",
        "for idx in range(n_dates):\n",
        "    print(\"{:25s}{:25s}\".format(x_example[idx], y_example[idx]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeR-1Hm5oFo_",
        "outputId": "a32817f0-dc89-4b9e-e92e-efc6e4785331"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input                    Target                   \n",
            "--------------------------------------------------\n",
            "July 22, 1344            1344-07-22               \n",
            "March 21, 7185           7185-03-21               \n",
            "January 02, 5192         5192-01-02               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#INPUT_OUTPUT_CHARS"
      ],
      "metadata": {
        "id": "AjkPHuAct72Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_CHARS = \"\".join(sorted(set(\"\".join(MONTHS) + \"0123456789, \")))\n",
        "OUTPUT_CHARS = \"0123456789-\"\n",
        "INPUT_CHARS, OUTPUT_CHARS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP1YNS6XoZZw",
        "outputId": "cf2cfee9-c629-473f-c4aa-bf71f22de99c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' ,0123456789ADFJMNOSabceghilmnoprstuvy', '0123456789-')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Input_Output_Tokenizer"
      ],
      "metadata": {
        "id": "UEhYuB4duC1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_chars = MONTHS + ['0123456789, ']\n",
        "output_chars = ['0123456789-']\n",
        "\n",
        "input_tokenizer = keras.preprocessing.text.Tokenizer(lower=False, char_level=True)\n",
        "input_tokenizer.fit_on_texts(sorted(set(input_chars)))\n",
        "input_vocab_size = len(input_tokenizer.word_index)\n",
        "\n",
        "output_tokenizer = keras.preprocessing.text.Tokenizer(lower=False, char_level=True)\n",
        "output_tokenizer.fit_on_texts(sorted(set(output_chars)))\n",
        "output_vocab_size = len(output_tokenizer.word_index)"
      ],
      "metadata": {
        "id": "OAsFfLXWo1Rp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_tokenizer.word_index)\n",
        "print(output_tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KizIjzmbqf0Q",
        "outputId": "b91605ee-8230-419a-c036-f974fd544070"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'e': 1, 'r': 2, 'u': 3, 'b': 4, 'a': 5, 'y': 6, 't': 7, 'c': 8, 'm': 9, 'J': 10, 'A': 11, 'p': 12, 'l': 13, 'n': 14, 'M': 15, 'o': 16, '0': 17, '1': 18, '2': 19, '3': 20, '4': 21, '5': 22, '6': 23, '7': 24, '8': 25, '9': 26, ',': 27, ' ': 28, 'i': 29, 'g': 30, 's': 31, 'D': 32, 'F': 33, 'h': 34, 'N': 35, 'v': 36, 'O': 37, 'S': 38}\n",
            "{'0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, '-': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = random_dates(3)\n",
        "\n",
        "print('-'*25)\n",
        "print(X[0])\n",
        "X = input_tokenizer.texts_to_sequences(X)\n",
        "print(X[0])\n",
        "X = input_tokenizer.sequences_to_texts(X)\n",
        "print(X[0][::2])\n",
        "\n",
        "print('-'*25)\n",
        "\n",
        "print(y[0])\n",
        "y = output_tokenizer.texts_to_sequences(y)\n",
        "print(y[0])\n",
        "y = output_tokenizer.sequences_to_texts(y)\n",
        "print(y[0][::2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGWcYoYYtO6s",
        "outputId": "b2e98fa3-96c5-4c05-8bd9-25c9d20452b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "April 09, 3947\n",
            "[11, 12, 2, 29, 13, 28, 17, 26, 27, 28, 20, 26, 21, 24]\n",
            "April 09, 3947\n",
            "-------------------------\n",
            "3947-04-09\n",
            "[4, 10, 5, 8, 11, 1, 5, 11, 1, 10]\n",
            "3947-04-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset_Generater"
      ],
      "metadata": {
        "id": "7RPhEGkzuG--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_date_strs(date_strs, tokenizer):\n",
        "    ids = [dt for dt in tokenizer.texts_to_sequences(date_strs)]\n",
        "    X = tf.ragged.constant(ids, ragged_rank=1)\n",
        "    return X.to_tensor() #ragged 텐서를 기본 텐서로 부족한 부분은 0 패딩토큰으로 채운다.\n",
        "\n",
        "def create_dataset(n_dates):\n",
        "    X, Y = random_dates(n_dates)\n",
        "    return prepare_date_strs(X, input_tokenizer), prepare_date_strs(Y, output_tokenizer)"
      ],
      "metadata": {
        "id": "mZ2Zw8YKp2gs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = create_dataset(10000)\n",
        "X_valid, Y_valid = create_dataset(2000)\n",
        "X_test, Y_test = create_dataset(2000)"
      ],
      "metadata": {
        "id": "jPvrYD8DtDxW"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0], Y_train[0], sep='\\n')\n",
        "print(input_tokenizer.sequences_to_texts([X_train[0].numpy()])[0][::2])\n",
        "print(output_tokenizer.sequences_to_texts([Y_train[0].numpy()])[0][::2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGavgDWOtExG",
        "outputId": "f32d0d79-8a39-4b3e-ab7e-e3fadab3ee4e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([11 12  2 29 13 28 17 26 27 28 20 26 21 24  0  0  0  0], shape=(18,), dtype=int32)\n",
            "tf.Tensor([ 4 10  5  8 11  1  5 11  1 10], shape=(10,), dtype=int32)\n",
            "April 09, 3947\n",
            "3947-04-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Seq2Seq_Model"
      ],
      "metadata": {
        "id": "wdc1-KQzuLO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 32\n",
        "#출력 최대 길이 : 10 (yyyy-mm-dd)\n",
        "max_output_length = Y_train.shape[-1]\n",
        "\n",
        "#인코더 디코더 구조를 사용한다.\n",
        "\n",
        "#인코더, 시퀀스 투 벡터 구조\n",
        "encoder = keras.models.Sequential([\n",
        "    keras.layers.Embedding(input_dim=input_vocab_size + 1, output_dim=embedding_size, input_shape=[None]),\n",
        "    keras.layers.LSTM(128)\n",
        "])\n",
        "\n",
        "decoder = keras.models.Sequential([\n",
        "    keras.layers.LSTM(128, return_sequences=True),\n",
        "    keras.layers.Dense(output_vocab_size + 1, activation='softmax')\n",
        "])\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    encoder,\n",
        "    #출력길이가 10이니깐 인코더 출력을 10번 반복해서, 디코더가 10개의 출력을 만들도록함\n",
        "    keras.layers.RepeatVector(max_output_length),\n",
        "    decoder\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u3NUSFrtE2-",
        "outputId": "e5ccf4bf-3506-4e06-9dea-99aabe817ce3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 128)               83680     \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 10, 128)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " sequential_1 (Sequential)   (None, 10, 12)            133132    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 216,812\n",
            "Trainable params: 216,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Nadam()\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yVNDBUquyezt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aic4qNg5ysUY",
        "outputId": "e3de6dd8-0739-40ae-b90e-25419e7840a0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 10s 11ms/step - loss: 1.7915 - accuracy: 0.3509 - val_loss: 1.3838 - val_accuracy: 0.4813\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.6229 - accuracy: 0.4306 - val_loss: 1.2769 - val_accuracy: 0.5559\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.1316 - accuracy: 0.6030 - val_loss: 0.9796 - val_accuracy: 0.6527\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.9460 - accuracy: 0.6666 - val_loss: 0.7504 - val_accuracy: 0.7247\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.6254 - accuracy: 0.7651 - val_loss: 0.5397 - val_accuracy: 0.7903\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.7077 - accuracy: 0.7503 - val_loss: 0.4770 - val_accuracy: 0.8150\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.3763 - accuracy: 0.8550 - val_loss: 0.5772 - val_accuracy: 0.7980\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2678 - accuracy: 0.9050 - val_loss: 0.2131 - val_accuracy: 0.9329\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1494 - accuracy: 0.9605 - val_loss: 0.1113 - val_accuracy: 0.9738\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0930 - accuracy: 0.9807 - val_loss: 0.0619 - val_accuracy: 0.9900\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0501 - accuracy: 0.9932 - val_loss: 0.0333 - val_accuracy: 0.9965\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0236 - accuracy: 0.9987 - val_loss: 0.0197 - val_accuracy: 0.9987\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0139 - accuracy: 0.9996 - val_loss: 0.0125 - val_accuracy: 0.9995\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0088 - accuracy: 0.9999 - val_loss: 0.0084 - val_accuracy: 0.9997\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9999\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 0.9999\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9999\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 0.9999\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9999\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vDkzHXF4UDN",
        "outputId": "31eab722-bf1e-42fc-fe35-73f57232e60f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0014783494407311082, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model_Return_To_Strings"
      ],
      "metadata": {
        "id": "U-kh3b2j4wwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ids_to_strings(ids, tokenizer):\n",
        "    return tokenizer.sequences_to_texts(ids)\n",
        "\n",
        "print('-'*25)\n",
        "#X_new = X_test[:3]\n",
        "#패딩이 없는 데이터셋이라 잘 예측을 못함\n",
        "X_new = prepare_date_strs([\"May 02, 2020\", \"July 14, 1789\"], input_tokenizer)\n",
        "X_samples = ids_to_strings(X_new.numpy(), input_tokenizer)\n",
        "print(*[x_sample[::2] for x_sample in X_samples], sep='\\n')\n",
        "\n",
        "\n",
        "print('-'*25)\n",
        "Y_new = np.argmax(model.predict(X_new), axis=-1)\n",
        "Y_new = ids_to_strings(Y_new, output_tokenizer)\n",
        "print(*[y_sample[::2] for y_sample in Y_new], sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCAewYw44wTh",
        "outputId": "ddc5165d-df7f-4acc-aa96-2b23ecb667e3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "May 02, 2020\n",
            "July 14, 1789\n",
            "-------------------------\n",
            "2020-01-02\n",
            "1789-01-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = X_train.shape[1]\n",
        "\n",
        "def prepare_date_strs_with_padded(date_strs, tokenizer):\n",
        "    X = prepare_date_strs(date_strs, tokenizer)\n",
        "    if X.shape[1] < max_input_length:\n",
        "        X = tf.pad(X, paddings=[[0,0], [0, max_input_length - X.shape[1]]])\n",
        "    return X\n",
        "\n",
        "\n",
        "print('-'*25)\n",
        "#패딩추가, 잘예측함\n",
        "X_new = prepare_date_strs_with_padded([\"May 02, 2020\", \"July 14, 1789\"], input_tokenizer)\n",
        "X_samples = ids_to_strings(X_new.numpy(), input_tokenizer)\n",
        "print(*[x_sample[::2] for x_sample in X_samples], sep='\\n')\n",
        "\n",
        "\n",
        "print('-'*25)\n",
        "Y_new = np.argmax(model.predict(X_new), axis=-1)\n",
        "Y_new = ids_to_strings(Y_new, output_tokenizer)\n",
        "print(*[y_sample[::2] for y_sample in Y_new], sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epYHWsGi79k0",
        "outputId": "24aac8b9-c48c-4572-e079-45400b80126f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "May 02, 2020\n",
            "July 14, 1789\n",
            "-------------------------\n",
            "2020-05-02\n",
            "1789-07-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9-2"
      ],
      "metadata": {
        "id": "rVtUzeUm9l6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decoder_Input_Target_Shift"
      ],
      "metadata": {
        "id": "codkA4LE-68c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sos_id = output_vocab_size + 1\n",
        "\n",
        "def shifted_output_sequences(Y):\n",
        "    sos_tokens = tf.fill(dims=(len(Y), 1), value=sos_id)\n",
        "    return tf.concat([sos_tokens, Y[:, :-1]], axis=1)\n",
        "\n",
        "#타깃을 오른쪽으로 한번 shift 하고 맨앞에 sos 토큰을 추가한 디코더 입력\n",
        "#원래는 인코더벡터를 복사해서 디코더에 입력했지만, 쉬프트된 타깃을 주입해서 이전타깃이 무엇인지 확인할수 있게한다.\n",
        "X_train_decoder = shifted_output_sequences(Y_train)\n",
        "X_valid_decoder = shifted_output_sequences(Y_valid)\n",
        "X_test_decoder = shifted_output_sequences(Y_test)"
      ],
      "metadata": {
        "id": "A_4wMFqR9nVj"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids_to_strings(X_train_decoder[:5].numpy(), output_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX978r__-kld",
        "outputId": "f0a601a4-1b60-4708-fcee-de44740838a6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['3 9 4 7 - 0 4 - 0',\n",
              " '7 6 9 2 - 0 5 - 0',\n",
              " '5 0 4 3 - 0 2 - 2',\n",
              " '5 7 1 7 - 0 5 - 0',\n",
              " '3 7 6 2 - 0 6 - 1']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "0hp8YMJC_BC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_embedding_size = 32\n",
        "decoder_embedding_size = 32\n",
        "\n",
        "lstm_units = 128\n",
        "\n",
        "encoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
        "encoder_embedding = keras.layers.Embedding(input_dim=input_vocab_size+1, output_dim=encoder_embedding_size)(encoder_input)\n",
        "#인코더의 출력벡터는 무시한다!!\n",
        "_, encoder_state_h, encoder_state_c = keras.layers.LSTM(lstm_units, return_state=True)(encoder_embedding)\n",
        "encoder_state = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "decoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
        "decoder_embedding = keras.layers.Embedding(output_vocab_size+1, decoder_embedding_size)(decoder_input)\n",
        "#대신 인코더의 LSTM의 상태와 디코더의 LSTM과 연결시킨다.\n",
        "decoder_lstm_output = keras.layers.LSTM(lstm_units, return_sequences=True)(decoder_embedding, initial_state=encoder_state)\n",
        "decoder_output = keras.layers.Dense(output_vocab_size+1, activation='softmax')(decoder_lstm_output)\n",
        "\n",
        "model = keras.models.Model(inputs=[encoder_input, decoder_input], outputs=[decoder_output])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7ZvSRmn-2XW",
        "outputId": "eab2c37f-e753-4cb0-9b02-4ebb2eb6ceef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_3 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_2 (Embedding)        (None, None, 32)     1248        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 32)     384         ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 128),        82432       ['embedding_2[0][0]']            \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, None, 128)    82432       ['embedding_3[0][0]',            \n",
            "                                                                  'lstm_2[0][1]',                 \n",
            "                                                                  'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, None, 12)     1548        ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 168,044\n",
            "Trainable params: 168,044\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([X_train, X_train_decoder], Y_train, epochs=10, validation_data=([X_valid, X_valid_decoder], Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_HI_KKmAwLO",
        "outputId": "2d4ad6b4-20dc-4706-ddf2-d5197fdf3da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 7s 10ms/step - loss: 1.6702 - accuracy: 0.3712 - val_loss: 1.4184 - val_accuracy: 0.4505\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.2351 - accuracy: 0.5254 - val_loss: 0.9711 - val_accuracy: 0.6467\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.6865 - accuracy: 0.7556 - val_loss: 0.3986 - val_accuracy: 0.8838\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2499 - accuracy: 0.9391 - val_loss: 0.1254 - val_accuracy: 0.9822\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0805 - accuracy: 0.9910 - val_loss: 0.0555 - val_accuracy: 0.9952\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0637 - accuracy: 0.9913 - val_loss: 0.0268 - val_accuracy: 0.9991\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0192 - accuracy: 0.9998 - val_loss: 0.0159 - val_accuracy: 0.9998\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ids_to_strings(np.argmax(model.predict([X_train[:5], X_train_decoder[:5]]), axis=-1), output_tokenizer))\n",
        "print(ids_to_strings(Y_train[:5].numpy(), output_tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxR3yt-2HEWs",
        "outputId": "a354bb2e-cc68-47a9-8bbe-7dcdee23d30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['5 7 1 7 - 0 5 - 0 5', '3 7 6 2 - 0 6 - 1 3', '6 5 6 2 - 1 2 - 0 1', '3 9 8 7 - 0 3 - 0 4', '4 8 3 0 - 0 6 - 0 5']\n",
            "['5 7 1 7 - 0 5 - 0 5', '3 7 6 2 - 0 6 - 1 3', '6 5 6 2 - 1 2 - 0 1', '3 9 8 7 - 0 3 - 0 4', '4 8 3 0 - 0 6 - 0 5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_new = output_tokenizer.texts_to_sequences([\"1789-07-14\", \"2020-05-01\"])\n",
        "\n",
        "def predict_date_strs(date_strs):\n",
        "    X = prepare_date_strs_with_padded(date_strs, input_tokenizer)\n",
        "    #X = date_strs\n",
        "    sos_id = output_vocab_size + 1\n",
        "    Y_pred = tf.fill(dims=(len(X), 1), value=sos_id)\n",
        "\n",
        "    for index in range(max_output_length):\n",
        "        X_decoder = tf.pad(Y_pred, [[0, 0], [0, max_output_length-index]])\n",
        "        Y_probas = tf.argmax(model.predict([X, X_decoder]), axis=-1, output_type=tf.int32)\n",
        "        Y_pred = tf.concat([Y_pred, Y_probas[:, index:index+1]], axis=1)\n",
        "    return ids_to_strings(Y_pred.numpy(), output_tokenizer)\n",
        "\n",
        "print(predict_date_strs([\"May 02, 2020\", \"July 14, 1789\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql1g0m9DHtk0",
        "outputId": "c0ed9c39-dc41-4058-aaf6-7c8937b998f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2 0 2 0 - 0 5 - 0 2', '1 7 8 9 - 0 7 - 1 4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9-3"
      ],
      "metadata": {
        "id": "O_tKelyG7zMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Addon_Sampler_Model"
      ],
      "metadata": {
        "id": "70us6ztfFHxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encoder_embedding_size = 32\n",
        "decoder_embedding_size = 32\n",
        "\n",
        "units = 128\n",
        "\n",
        "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
        "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
        "\n",
        "encoder_embeddings = keras.layers.Embedding(input_vocab_size + 1, encoder_embedding_size)(encoder_inputs)\n",
        "\n",
        "encoder = keras.layers.LSTM(units, return_state=True)\n",
        "encoder_output, state_h, state_c = encoder(encoder_embeddings)\n",
        "encoder_state = [state_h, state_c]\n",
        "\n",
        "\n",
        "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
        "\n",
        "decoder_embedding_layer = keras.layers.Embedding(output_vocab_size + 2, decoder_embedding_size)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "#sampler\n",
        "sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "\n",
        "decoder_cell = keras.layers.LSTMCell(units)\n",
        "output_layer = keras.layers.Dense(output_vocab_size+1)\n",
        "\n",
        "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler, output_layer=output_layer)\n",
        "\n",
        "final_output, final_state, final_sequence_lengths = decoder(decoder_embeddings, initial_state=encoder_state)\n",
        "Y_proba = keras.layers.Activation('softmax')(final_output.rnn_output)\n",
        "\n",
        "model = keras.models.Model(inputs=[encoder_inputs, decoder_inputs], outputs=[Y_proba])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Zb0E2Sdb70ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([X_train, X_train_decoder], Y_train, epochs=9, validation_data=([X_valid, X_valid_decoder], Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LegU0AxjBJsv",
        "outputId": "539e61e3-ba4e-48cc-c5eb-1095c7555ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "313/313 [==============================] - 14s 33ms/step - loss: 1.6734 - accuracy: 0.3760 - val_loss: 1.4363 - val_accuracy: 0.4451\n",
            "Epoch 2/9\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 1.1483 - accuracy: 0.5837 - val_loss: 0.8829 - val_accuracy: 0.6852\n",
            "Epoch 3/9\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 0.5990 - accuracy: 0.7951 - val_loss: 0.3506 - val_accuracy: 0.8874\n",
            "Epoch 4/9\n",
            "313/313 [==============================] - 10s 31ms/step - loss: 0.2181 - accuracy: 0.9460 - val_loss: 0.1073 - val_accuracy: 0.9862\n",
            "Epoch 5/9\n",
            "313/313 [==============================] - 10s 31ms/step - loss: 0.0811 - accuracy: 0.9909 - val_loss: 0.0420 - val_accuracy: 0.9980\n",
            "Epoch 6/9\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 0.0295 - accuracy: 0.9993 - val_loss: 0.0233 - val_accuracy: 0.9995\n",
            "Epoch 7/9\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 0.0527 - accuracy: 0.9916 - val_loss: 0.0155 - val_accuracy: 0.9998\n",
            "Epoch 8/9\n",
            "313/313 [==============================] - 10s 30ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9998\n",
            "Epoch 9/9\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_date_strs([\"May 02, 2020\", \"July 14, 1789\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDEEg6iVC1OJ",
        "outputId": "42f2c43b-c437-430b-b6e2-209a04ff0a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2 0 2 0 - 0 5 - 0 2', '1 7 8 9 - 0 7 - 1 4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GreedyEmbeddingSampler"
      ],
      "metadata": {
        "id": "XhyzO3P0FF7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_sampler = tfa.seq2seq.sampler.GreedyEmbeddingSampler(embedding_fn=decoder_embedding_layer)\n",
        "\n",
        "inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, inference_sampler, output_layer=output_layer, maximum_iterations=max_output_length)\n",
        "batch_size = tf.shape(encoder_inputs)[:1]\n",
        "start_tokens = tf.fill(dims=batch_size, value=sos_id)\n",
        "final_outputs, final_state, final_sequence_lengths = inference_decoder(start_tokens, initial_state=encoder_state, start_tokens=start_tokens, end_token=0)\n",
        "\n",
        "inference_model = keras.models.Model(inputs=[encoder_inputs], outputs=[final_outputs.sample_id])"
      ],
      "metadata": {
        "id": "q6pXkCJEHQRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fast_predict_date_strs(date_strs):\n",
        "    X = prepare_date_strs_with_padded(date_strs, input_tokenizer)\n",
        "    Y_pred = inference_model.predict(X)\n",
        "    return ids_to_strings(Y_pred, output_tokenizer)"
      ],
      "metadata": {
        "id": "sCRLYyTrHjei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "886WbTvKIGF1",
        "outputId": "b314efe0-1bd5-4ccc-e47a-b90af5c54f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 450 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit fast_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PS84z05UILLZ",
        "outputId": "f7955a0a-5218-4dff-dbbf-d90e21b84cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 13.47 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 41.8 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9-4"
      ],
      "metadata": {
        "id": "Yel4zMzBJjft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Schedule_Model"
      ],
      "metadata": {
        "id": "I8ONihUwLTiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 20\n",
        "encoder_embedding_size = 32\n",
        "decoder_embedding_size = 32\n",
        "units = 128\n",
        "\n",
        "#encoder\n",
        "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
        "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
        "\n",
        "encoder_embeddings = keras.layers.Embedding(input_vocab_size + 1, encoder_embedding_size)(encoder_inputs)\n",
        "\n",
        "encoder = keras.layers.LSTM(units, return_state=True)\n",
        "encoder_output, state_h, state_c = encoder(encoder_embeddings)\n",
        "encoder_state = [state_h, state_c]\n",
        "\n",
        "#decoder\n",
        "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\\\n",
        "\n",
        "decoder_embedding_layer = keras.layers.Embedding(output_vocab_size + 2, decoder_embedding_size)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "#sampler\n",
        "#훈련할때 점진적으로 타깃에서 예측한 값을 입력으로 보낸다.\n",
        "sampler = tfa.seq2seq.sampler.ScheduledEmbeddingTrainingSampler(sampling_probability=0., embedding_fn=decoder_embedding_layer)\n",
        "sampler.sampling_probability = tf.Variable(0.)\n",
        "\n",
        "decoder_cell = keras.layers.LSTMCell(units)\n",
        "output_layer = keras.layers.Dense(output_vocab_size+1)\n",
        "\n",
        "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler, output_layer=output_layer)\n",
        "\n",
        "final_output, final_state, final_sequence_lengths = decoder(decoder_embeddings, initial_state=encoder_state)\n",
        "Y_proba = keras.layers.Activation('softmax')(final_output.rnn_output)\n",
        "\n",
        "optimizer = keras.optimizers.Nadam()\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "vOrjxr1jJlGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Schedule_Sampling_Probability_Callback"
      ],
      "metadata": {
        "id": "BP1TUkC4LObY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#매 에폭이 끝날때마다 예측한 값을 입력으로 보낼 확률을 올려줌\n",
        "def update_sampling_probability(epoch, logs):\n",
        "    proba = min(1.0, epoch / (n_epochs - 10))\n",
        "    sampler.sampling_probability.assign(proba)\n",
        "\n",
        "sampling_probability_cb = keras.callbacks.LambdaCallback(on_epoch_begin=update_sampling_probability)"
      ],
      "metadata": {
        "id": "CYzNqEi3KrUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([X_train, X_train_decoder], Y_train, epochs=n_epochs, \n",
        "                    validation_data=([X_valid, X_valid_decoder], Y_valid), \n",
        "                    callbacks=[sampling_probability_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upq7F_zBK28w",
        "outputId": "02bec7e9-ed38-438b-b6b7-76c7dcc15c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 14s 33ms/step - loss: 0.0250 - accuracy: 0.9957 - val_loss: 0.0051 - val_accuracy: 0.9999\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 10s 31ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 8.7203e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 10s 31ms/step - loss: 6.5597e-04 - accuracy: 1.0000 - val_loss: 7.1708e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 10s 31ms/step - loss: 5.0408e-04 - accuracy: 1.0000 - val_loss: 5.5726e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 10s 30ms/step - loss: 0.1314 - accuracy: 0.9699 - val_loss: 0.0056 - val_accuracy: 0.9998\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 0.9999\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 10s 30ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9999\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 10s 30ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 0.9999\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 10s 30ms/step - loss: 8.5795e-04 - accuracy: 1.0000 - val_loss: 9.4585e-04 - val_accuracy: 0.9999\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 6.7363e-04 - accuracy: 1.0000 - val_loss: 7.5837e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 10s 31ms/step - loss: 5.4429e-04 - accuracy: 1.0000 - val_loss: 6.2861e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 10s 31ms/step - loss: 4.4745e-04 - accuracy: 1.0000 - val_loss: 5.1357e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 3.7251e-04 - accuracy: 1.0000 - val_loss: 4.4432e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 3.1222e-04 - accuracy: 1.0000 - val_loss: 3.6976e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 9s 30ms/step - loss: 2.6348e-04 - accuracy: 1.0000 - val_loss: 3.1881e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 10s 30ms/step - loss: 2.2464e-04 - accuracy: 1.0000 - val_loss: 2.7817e-04 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference_SampleEmbeddingSampler"
      ],
      "metadata": {
        "id": "a8mUMDlPL1TJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_temperature = tf.Variable(1.)\n",
        "\n",
        "inference_sampler = tfa.seq2seq.sampler.SampleEmbeddingSampler(embedding_fn=decoder_embedding_layer, softmax_temperature=softmax_temperature)\n",
        "inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, inference_sampler, output_layer=output_layer, maximum_iterations=max_output_length)\n",
        "\n",
        "batch_size = tf.shape(encoder_inputs)[:1]\n",
        "start_tokens = tf.fill(dims=batch_size, value=sos_id)\n",
        "\n",
        "final_outputs, final_state, final_sequence_lengths = inference_decoder(start_tokens, initial_state=encoder_state, start_tokens=start_tokens, end_token=0)\n",
        "\n",
        "inference_model = keras.models.Model(inputs=[encoder_inputs], outputs=[final_outputs.sample_id])"
      ],
      "metadata": {
        "id": "hZ9l0idCL0rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def creative_predict_date_strs(date_strs, temperature=1.0):\n",
        "    softmax_temperature.assign(temperature)\n",
        "    X = prepare_date_strs_with_padded(date_strs, input_tokenizer)\n",
        "    Y_pred = inference_model.predict(X)\n",
        "    return ids_to_strings(Y_pred, output_tokenizer)\n",
        "\n",
        "print(creative_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"]))\n",
        "print(creative_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"], 5.0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLa2btjIMDtT",
        "outputId": "6e4c0982-fe09-462d-e092-86749881f280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0 4 1 7 3 4 8 3 5 8', '- 9 8 0 4 7 4 0 0']\n",
            "['9 1 9 2 1 4 2 6 0', '8 8 3 3 - 0 6 4 2 1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9-5"
      ],
      "metadata": {
        "id": "atNGcKddjGCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Subclassing_Model_Attention"
      ],
      "metadata": {
        "id": "6AdcCRAijJyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DateTranslate(keras.models.Model):\n",
        "    def __init__(self, units=128, encoder_embedding_size=32, decoder_embedding_size=32, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        #encoder\n",
        "        self.encoder_embedding = keras.layers.Embedding(input_dim=input_vocab_size+1, output_dim=encoder_embedding_size)\n",
        "        self.encoder = keras.layers.LSTM(units, return_sequences=True, return_state=True)\n",
        "        \n",
        "        #decoder\n",
        "        # - embedding\n",
        "        self.decoder_embedding = keras.layers.Embedding(input_dim=output_vocab_size+2, output_dim=decoder_embedding_size)\n",
        "        \n",
        "        # - attention\n",
        "        self.attention = tfa.seq2seq.LuongAttention(units)\n",
        "        decoder_inner_cell = keras.layers.LSTMCell(units)\n",
        "        self.decoder_cell = tfa.seq2seq.AttentionWrapper(cell = decoder_inner_cell, attention_mechanism=self.attention)\n",
        "\n",
        "        # - basic decoder \n",
        "        output_layer = keras.layers.Dense(output_vocab_size+1)\n",
        "        self.decoder = tfa.seq2seq.BasicDecoder(cell=self.decoder_cell, sampler=tfa.seq2seq.sampler.TrainingSampler(), output_layer=output_layer)\n",
        "        \n",
        "        # - inference decoder\n",
        "        self.inference_decoder = tfa.seq2seq.BasicDecoder(\n",
        "            cell=self.decoder_cell, \n",
        "            sampler=tfa.seq2seq.sampler.GreedyEmbeddingSampler(embedding_fn=self.decoder_embedding),\n",
        "            output_layer=output_layer,\n",
        "            maximum_iterations=max_output_length\n",
        "            )\n",
        "        \n",
        "    def call(self, inputs, training=None):\n",
        "\n",
        "        encoder_input, decoder_input = inputs\n",
        "\n",
        "        encoder_embeddings = self.encoder_embedding(encoder_input)\n",
        "        encoder_outputs, state_h, state_c = self.encoder(encoder_embeddings, training=training)\n",
        "        encoder_state = [state_h, state_c]\n",
        "\n",
        "        self.attention(encoder_outputs, setup_memory=True)\n",
        "\n",
        "        decoder_embeddings = self.decoder_embedding(decoder_input)\n",
        "        decoder_initial_state = self.decoder_cell.get_initial_state(decoder_embeddings)\n",
        "        decoder_initial_state = decoder_initial_state.clone(cell_state=encoder_state)\n",
        "        if training:\n",
        "            decoder_outputs, _, _ = self.decoder(decoder_embeddings, initial_state=decoder_initial_state, training=training)\n",
        "        else:\n",
        "            start_tokens = tf.zeros_like(encoder_input[:, 0]) + sos_id\n",
        "            decoder_outputs, _, _ = self.inference_decoder(decoder_embeddings, initial_state=decoder_initial_state, start_tokens=start_tokens, end_token=0)\n",
        "        \n",
        "        return tf.nn.softmax(decoder_outputs.rnn_output)"
      ],
      "metadata": {
        "id": "feGuNn1ujG6o"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DateTranslate()\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DdC7tnssoVuv"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([X_train, X_train_decoder], Y_train, epochs=25, validation_data=([X_valid, X_valid_decoder], Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy0x9y5HoeTt",
        "outputId": "42d4aa87-1358-4a22-d10f-80bd662b40dd"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "313/313 [==============================] - 19s 49ms/step - loss: 2.1546 - accuracy: 0.2259 - val_loss: 2.0625 - val_accuracy: 0.2520\n",
            "Epoch 2/25\n",
            "313/313 [==============================] - 14s 46ms/step - loss: 1.8142 - accuracy: 0.3426 - val_loss: 1.3794 - val_accuracy: 0.4868\n",
            "Epoch 3/25\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 1.2884 - accuracy: 0.5156 - val_loss: 1.2056 - val_accuracy: 0.5426\n",
            "Epoch 4/25\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 1.4055 - accuracy: 0.4971 - val_loss: 1.3460 - val_accuracy: 0.5135\n",
            "Epoch 5/25\n",
            "313/313 [==============================] - 14s 46ms/step - loss: 1.2818 - accuracy: 0.5337 - val_loss: 4.5334 - val_accuracy: 0.0550\n",
            "Epoch 6/25\n",
            "313/313 [==============================] - 14s 46ms/step - loss: 1.1963 - accuracy: 0.5462 - val_loss: 1.1721 - val_accuracy: 0.5454\n",
            "Epoch 7/25\n",
            "313/313 [==============================] - 14s 46ms/step - loss: 1.1563 - accuracy: 0.5514 - val_loss: 1.1474 - val_accuracy: 0.5561\n",
            "Epoch 8/25\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 1.1538 - accuracy: 0.5580 - val_loss: 1.1142 - val_accuracy: 0.5720\n",
            "Epoch 9/25\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 1.0435 - accuracy: 0.5927 - val_loss: 1.0687 - val_accuracy: 0.5989\n",
            "Epoch 10/25\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.8113 - accuracy: 0.6629 - val_loss: 0.9171 - val_accuracy: 0.6536\n",
            "Epoch 11/25\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.5813 - accuracy: 0.7441 - val_loss: 0.8241 - val_accuracy: 0.7135\n",
            "Epoch 12/25\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.3955 - accuracy: 0.8371 - val_loss: 0.4838 - val_accuracy: 0.8498\n",
            "Epoch 13/25\n",
            "313/313 [==============================] - 14s 46ms/step - loss: 0.2807 - accuracy: 0.9080 - val_loss: 0.2931 - val_accuracy: 0.9288\n",
            "Epoch 14/25\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.1773 - accuracy: 0.9632 - val_loss: 0.1515 - val_accuracy: 0.9699\n",
            "Epoch 15/25\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.1176 - accuracy: 0.9801 - val_loss: 0.1672 - val_accuracy: 0.9651\n",
            "Epoch 16/25\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.0791 - accuracy: 0.9903 - val_loss: 0.0635 - val_accuracy: 0.9952\n",
            "Epoch 17/25\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.1038 - accuracy: 0.9814 - val_loss: 0.0636 - val_accuracy: 0.9913\n",
            "Epoch 18/25\n",
            "313/313 [==============================] - 14s 46ms/step - loss: 0.0412 - accuracy: 0.9971 - val_loss: 0.0360 - val_accuracy: 0.9977\n",
            "Epoch 19/25\n",
            "313/313 [==============================] - 14s 46ms/step - loss: 0.0298 - accuracy: 0.9978 - val_loss: 0.0244 - val_accuracy: 0.9997\n",
            "Epoch 20/25\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.0223 - accuracy: 0.9987 - val_loss: 0.0167 - val_accuracy: 0.9999\n",
            "Epoch 21/25\n",
            "313/313 [==============================] - 14s 46ms/step - loss: 0.0451 - accuracy: 0.9935 - val_loss: 0.0152 - val_accuracy: 0.9998\n",
            "Epoch 22/25\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.0120 - accuracy: 0.9999 - val_loss: 0.0117 - val_accuracy: 0.9999\n",
            "Epoch 23/25\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.0514 - accuracy: 0.9904 - val_loss: 0.0235 - val_accuracy: 0.9987\n",
            "Epoch 24/25\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.0115 - accuracy: 0.9999 - val_loss: 0.0099 - val_accuracy: 0.9999\n",
            "Epoch 25/25\n",
            "313/313 [==============================] - 14s 45ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fast_predict_date_strs_v2(date_strs):\n",
        "    X = prepare_date_strs_with_padded(date_strs, input_tokenizer)\n",
        "    X_decoder = tf.zeros(shape=(len(X), max_output_length), dtype=tf.int32)\n",
        "    Y_probas = model.predict([X, X_decoder])\n",
        "    Y_pred = tf.argmax(Y_probas, axis=-1)\n",
        "    return ids_to_strings(Y_pred.numpy(), output_tokenizer)\n",
        "\n",
        "fast_predict_date_strs_v2([\"July 14, 1789\", \"May 01, 2020\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHSkFNWxVx_v",
        "outputId": "85add9e4-db09-4239-d1f9-089e1f79f4f5"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1 7 8 9 - 0 7 - 1 4', '2 0 2 0 - 0 5 - 0 1']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10"
      ],
      "metadata": {
        "id": "tvTws_pmYFs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "metadata": {
        "id": "aEN1Ba5RYFH2"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_zip = keras.utils.get_file('spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip', extract=True)\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIHzRUnlYL3S",
        "outputId": "48efdb4c-9222-4369-bec3-c537da5c8f4d"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n",
            "2654208/2638744 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 유니코드 파일을 아스키 코드 파일로 변환합니다.\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # 단어와 단어 뒤에 오는 구두점(.)사이에 공백을 생성합니다.\n",
        "  # 예시: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # 참고:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")을 제외한 모든 것을 공백으로 대체합니다.\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # 모델이 예측을 시작하거나 중단할 때를 알게 하기 위해서\n",
        "  # 문장에 start와 end 토큰을 추가합니다.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "metadata": {
        "id": "dBBwufoBYawX"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(path, num_examples):\n",
        "\n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "    \n",
        "    return zip(*word_pairs)"
      ],
      "metadata": {
        "id": "V4JONHG1a70f"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AttA7p9jcGvQ",
        "outputId": "1032c8f7-ec22-4180-e3a3-6e99bd04d42c"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
            "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(lang):\n",
        "    lang_tokenizer = keras.preprocessing.text.Tokenizer(filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    \n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "\n",
        "    return tensor, lang_tokenizer"
      ],
      "metadata": {
        "id": "MwniMgEAcG19"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "    target_lang, input_lang = create_dataset(path, num_examples)\n",
        "\n",
        "    input_tensor, input_lang_tokenizer = tokenize(input_lang)\n",
        "    target_tensor, target_lang_tokenizer = tokenize(target_lang)\n",
        "\n",
        "    return input_tensor, target_tensor, input_lang_tokenizer, target_lang_tokenizer"
      ],
      "metadata": {
        "id": "SaGzE8vheg6q"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_examples = 30000\n",
        "input_tensor, target_tensor, input_lang_tokenizer, target_lang_tokenizer = load_dataset(path_to_file, num_examples=num_examples)\n",
        "\n",
        "max_length_input, max_length_target = input_tensor.shape[-1], target_tensor.shape[-1]"
      ],
      "metadata": {
        "id": "LstNLY6ufKRD"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, Y_train, Y_valid = train_test_split(input_tensor, target_tensor, test_size=0.2)"
      ],
      "metadata": {
        "id": "cV_MRRcDfrl8"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#tf.data.Dataset_Create"
      ],
      "metadata": {
        "id": "Th_9sCndgaDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(X_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(X_train) // BATCH_SIZE\n",
        "\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_input_size = len(input_lang_tokenizer.word_index) + 1\n",
        "vocab_target_size = len(target_lang_tokenizer.word_index) + 1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True).prefetch(1)"
      ],
      "metadata": {
        "id": "j8M5c3JpgNjE"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_input_size, vocab_target_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcSkdSnEhJvS",
        "outputId": "2a1c8a52-ac02-48b4-dfbc-60579fb7d68f"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9414, 4935)"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(keras.models.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.batch_size = batch_size\n",
        "        self.encoder_units = encoder_units\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = keras.layers.GRU(self.encoder_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, input, hidden_state):\n",
        "        x = self.embedding(input)\n",
        "        output, state = self.gru(x, initial_state=hidden_state)\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_size, self.encoder_units))"
      ],
      "metadata": {
        "id": "mMJsPKl8i6Zw"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahadanauAttention(keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.W1 = keras.layers.Dense(units)\n",
        "        self.W2 = keras.layers.Dense(units)\n",
        "        self.V = keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        #score : FC(tanh(FC(EO) + FC(H)))\n",
        "\n",
        "        #query hidden state : (batch_size, hidden_size)\n",
        "        #query_with_time_axis : (batch_size, 1, hidden_size)\n",
        "        #values : (batch_size, max_len, hidden_size)\n",
        "        query_with_time_axis = tf.expand_dims(query, axis=1)\n",
        "\n",
        "        #score : (batch_size, max_len, 1)\n",
        "        score = self.V(\n",
        "            tf.nn.tanh(\n",
        "                #(batch_size, max_len, units)\n",
        "                self.W1(query_with_time_axis) + self.W2(values)\n",
        "            )\n",
        "        )\n",
        "\n",
        "        #(batch_size, max_len, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        \n",
        "        #가중치 합\n",
        "        #context_vector : (batch_size, hidden_size)\n",
        "        context_vector = tf.reduce_sum(attention_weights * values, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights\n"
      ],
      "metadata": {
        "id": "ZeSpgIeQkFyE"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(keras.models.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.decoder_units = decoder_units\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = keras.layers.GRU(self.decoder_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "        self.fc = keras.layers.Dense(vocab_size)\n",
        "\n",
        "        self.attention = BahadanauAttention(self.decoder_units)\n",
        "\n",
        "    def call(self, x, hidden_state, encoder_output):\n",
        "        #x : (batch_size, 1)\n",
        "        #hidden_state : (batch_size, hidden_size)\n",
        "        #encoder_output : (batch_size, max_len, hidden_size)\n",
        "        context_vector, attention_weights = self.attention(hidden_state, encoder_output)\n",
        "        \n",
        "        #embedded x : (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        #concated x : (batch_size, 1, hidden_size + embedding_dim)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, axis=1), x], axis=-1)\n",
        "\n",
        "        output, state = self.gru(x)\n",
        "        \n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state, attention_weights"
      ],
      "metadata": {
        "id": "6E-xv0y2qaX3"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(vocab_input_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_target_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_input, sample_target = next(iter(dataset.take(1)))\n",
        "print(\"input, target shape : (batch_size, max_input_len), (batch_size, max_target_len)\",sample_input.shape, sample_target.shape)\n",
        "encoder_output, hidden_state = encoder(sample_input, encoder.initialize_hidden_state())\n",
        "print(\"encoder output : (batch_size, max_input_len, units)\", encoder_output.shape)\n",
        "print(\"hidden state : (batch_size, units)\", hidden_state.shape)\n",
        "decoder_output, hidden_state, attention_weights = decoder(tf.random.uniform((BATCH_SIZE, 1)), hidden_state, encoder_output)\n",
        "print(\"decoder output : (batch_size, vocab_output_size)\", decoder_output.shape)\n",
        "print(\"decoder state : (batch_size, decoder_units)\", hidden_state.shape)\n",
        "print(\"attention weights : (batch_size, max_input_len, 1)\", attention_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDd4WButu_wT",
        "outputId": "4903c463-e51c-44b5-93c8-bc909aef587f"
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input, target shape : (batch_size, max_input_len), (batch_size, max_target_len) (64, 16) (64, 11)\n",
            "encoder output : (batch_size, max_input_len, units) (64, 16, 1024)\n",
            "hidden state : (batch_size, units) (64, 1024)\n",
            "decoder output : (batch_size, vocab_output_size) (64, 4935)\n",
            "decoder state : (batch_size, decoder_units) (64, 1024)\n",
            "attention weights : (batch_size, max_input_len, 1) (64, 16, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Adam()\n",
        "loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_fn(y_real, y_pred):\n",
        "    #타깃이 패딩 토큰이면 무시하는 마스킹 생성\n",
        "    mask = tf.math.logical_not(tf.math.equal(y_real, 0))\n",
        "    loss_ = loss_object(y_real, y_pred)\n",
        "    \n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "id": "msVUqcAbtkQ6"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive_model_path = 'drive/MyDrive/Model/spa2eng'\n",
        "checkpoint_dir = drive_model_path + '/training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder)"
      ],
      "metadata": {
        "id": "fPoUMhtWugWp"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(input, target, encoder_hidden):\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        encoder_output, encoder_hidden = encoder(input, encoder_hidden)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        \n",
        "        #디코더 시작은 무조건 <start> 토큰 하나\n",
        "        decoder_input = tf.expand_dims([target_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "        \n",
        "        for t in range(1, target.shape[-1]):\n",
        "            predictions, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_output)\n",
        "\n",
        "            loss += loss_fn(target[:, t], predictions)\n",
        "\n",
        "            #다음 인풋\n",
        "            decoder_input = tf.expand_dims(target[:,t], 1)\n",
        "    \n",
        "    batch_loss = (loss / int(target.shape[1]))\n",
        "    \n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    \n",
        "    return batch_loss"
      ],
      "metadata": {
        "id": "870-YZny2LJH"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    encoder_state = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (input, target)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(input, target, encoder_state)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "    \n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
        "    print('Time taken for 1 epoch {:.4f} sec\\n'.format(time.time() - start))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEVKYaVi4mkF",
        "outputId": "cf5b2a78-8874-4fd7-9298-910116dfe84f"
      },
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 1024)\n",
            "Epoch 1 Batch 0 Loss 0.0639\n",
            "Epoch 1 Batch 100 Loss 0.0715\n",
            "Epoch 1 Batch 200 Loss 0.1024\n",
            "Epoch 1 Batch 300 Loss 0.0810\n",
            "Epoch 1 Loss 0.0817\n",
            "Time taken for 1 epoch 27.4474 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.0307\n",
            "Epoch 2 Batch 100 Loss 0.0600\n",
            "Epoch 2 Batch 200 Loss 0.0649\n",
            "Epoch 2 Batch 300 Loss 0.0638\n",
            "Epoch 2 Loss 0.0726\n",
            "Time taken for 1 epoch 21.0521 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.0469\n",
            "Epoch 3 Batch 100 Loss 0.0422\n",
            "Epoch 3 Batch 200 Loss 0.0576\n",
            "Epoch 3 Batch 300 Loss 0.0944\n",
            "Epoch 3 Loss 0.0667\n",
            "Time taken for 1 epoch 20.0975 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.0713\n",
            "Epoch 4 Batch 100 Loss 0.0441\n",
            "Epoch 4 Batch 200 Loss 0.0962\n",
            "Epoch 4 Batch 300 Loss 0.0728\n",
            "Epoch 4 Loss 0.0614\n",
            "Time taken for 1 epoch 21.3032 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.0488\n",
            "Epoch 5 Batch 100 Loss 0.0399\n",
            "Epoch 5 Batch 200 Loss 0.0519\n",
            "Epoch 5 Batch 300 Loss 0.0851\n",
            "Epoch 5 Loss 0.0578\n",
            "Time taken for 1 epoch 20.0940 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.0855\n",
            "Epoch 6 Batch 100 Loss 0.0691\n",
            "Epoch 6 Batch 200 Loss 0.0502\n",
            "Epoch 6 Batch 300 Loss 0.0722\n",
            "Epoch 6 Loss 0.0572\n",
            "Time taken for 1 epoch 21.0257 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.0376\n",
            "Epoch 7 Batch 100 Loss 0.0388\n",
            "Epoch 7 Batch 200 Loss 0.0489\n",
            "Epoch 7 Batch 300 Loss 0.0931\n",
            "Epoch 7 Loss 0.0597\n",
            "Time taken for 1 epoch 20.0875 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0457\n",
            "Epoch 8 Batch 100 Loss 0.0492\n",
            "Epoch 8 Batch 200 Loss 0.0551\n",
            "Epoch 8 Batch 300 Loss 0.0897\n",
            "Epoch 8 Loss 0.0568\n",
            "Time taken for 1 epoch 21.3604 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0378\n",
            "Epoch 9 Batch 100 Loss 0.0243\n",
            "Epoch 9 Batch 200 Loss 0.0637\n",
            "Epoch 9 Batch 300 Loss 0.0448\n",
            "Epoch 9 Loss 0.0527\n",
            "Time taken for 1 epoch 20.0907 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0293\n",
            "Epoch 10 Batch 100 Loss 0.0469\n",
            "Epoch 10 Batch 200 Loss 0.0479\n",
            "Epoch 10 Batch 300 Loss 0.0375\n",
            "Epoch 10 Loss 0.0488\n",
            "Time taken for 1 epoch 21.0201 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(sentence):\n",
        "    #어텐션 가중치 출력을 위한 변수\n",
        "    attention_plot = np.zeros((max_length_target, max_length_input))\n",
        "\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [input_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_input ,padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = tf.zeros((1, encoder.encoder_units))\n",
        "    encoder_output, encoder_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "    decoder_input = tf.expand_dims([target_lang_tokenizer.word_index['<start>']], axis=1)\n",
        "\n",
        "    for t in range(max_length_target):\n",
        "        predictions, decoder_hidden, attention_weights = decoder(decoder_input, decoder_hidden, encoder_output)\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        prediction_id = tf.argmax(predictions[0]).numpy()\n",
        "        \n",
        "        result += target_lang_tokenizer.index_word[prediction_id] + ' '\n",
        "\n",
        "        if target_lang_tokenizer.index_word[prediction_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "        \n",
        "        decoder_input = tf.expand_dims([prediction_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "metadata": {
        "id": "VUvV9eXA-gfY"
      },
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "rRYlFxkWGHKJ"
      },
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "metadata": {
        "id": "gAL7shBnGJ4o"
      },
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvicmxUoGUkx",
        "outputId": "1b5cd4bd-02d5-4f5d-fbb2-33c0bf07a5e6"
      },
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f1db13aab50>"
            ]
          },
          "metadata": {},
          "execution_count": 337
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(u'hace mucho frio aqui.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "pru5vrCrGN3M",
        "outputId": "1105409a-c69d-4b69-89ed-97543b55c703"
      },
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it is very cold here . <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(u'esta es mi vida.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "Ur6qqEdrV67D",
        "outputId": "2e9fd787-9794-456c-c888-f26beaf22047"
      },
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> esta es mi vida . <end>\n",
            "Predicted translation: this is my life . <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(u'¿todavia estan en casa?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "O0RDUIQKWAuv",
        "outputId": "d9ac761b-32a3-4876-a637-6d1370e9d744"
      },
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> ¿ todavia estan en casa ? <end>\n",
            "Predicted translation: are you still home ? <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(u'trata de averiguarlo.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "k2GjjX_jWKu1",
        "outputId": "c7ab11f8-da08-48dd-e92a-f07f5f1f7dce"
      },
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> trata de averiguarlo . <end>\n",
            "Predicted translation: try to figure it out . <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}