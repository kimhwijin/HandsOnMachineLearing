{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HOML_Exercise_16.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1Fr4Ovc4aFGXpKVcgJ_lrNHnjtxWvrN3l",
      "authorship_tag": "ABX9TyO+asJ+9g57O3Ga3BP8Kc5M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimhwijin/HandsOnMachineLearing/blob/main/HOML_Exercise_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 327,
      "metadata": {
        "id": "E8hNZpeOZvOV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "cOBH9WrNgMyU"
      },
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8."
      ],
      "metadata": {
        "id": "-I_I4OsAaA8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grammer_StringGenerater"
      ],
      "metadata": {
        "id": "W3a5SCznh6zb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#문법에 맞는 문자열을 반환하는 함수\n",
        "\n",
        "#문법, LR table 과 비슷함\n",
        "default_reber_grammar = [\n",
        "    [(\"B\", 1)],           # (state 0) =B=>(state 1)\n",
        "    [(\"T\", 2), (\"P\", 3)], # (state 1) =T=>(state 2) or =P=>(state 3)\n",
        "    [(\"S\", 2), (\"X\", 4)], # (state 2) =S=>(state 2) or =X=>(state 4)\n",
        "    [(\"T\", 3), (\"V\", 5)], # and so on...\n",
        "    [(\"X\", 3), (\"S\", 6)],\n",
        "    [(\"P\", 4), (\"V\", 6)],\n",
        "    #마지막\n",
        "    [(\"E\", None)]]        # (state 6) =E=>(terminal state)\n",
        "\n",
        "embedded_reber_grammar = [\n",
        "    [(\"B\", 1)],\n",
        "    [(\"T\", 2), (\"P\", 3)],\n",
        "    [(default_reber_grammar, 4)],\n",
        "    [(default_reber_grammar, 5)],\n",
        "    [(\"T\", 6)],\n",
        "    [(\"P\", 6)],\n",
        "    #마지막\n",
        "    [(\"E\", None)]]\n",
        "\n",
        "def generate_string(grammar):\n",
        "    state = 0\n",
        "    output=[]\n",
        "    while state is not None:\n",
        "        index = np.random.randint(len(grammar[state]))\n",
        "        #다음 문자와 상태\n",
        "        production, state = grammar[state][index]\n",
        "        if isinstance(production, list):\n",
        "            production = generate_string(grammar=production)\n",
        "        output.append(production)\n",
        "    return \"\".join(output)"
      ],
      "metadata": {
        "id": "NTSOz5XNZ_Mh"
      },
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(25):\n",
        "    #25개의 문자열 생성\n",
        "    print(generate_string(default_reber_grammar), end=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeL37UA2a9ss",
        "outputId": "90074807-a79a-415c-d33b-4337c7b67201"
      },
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BTXXTTVPXTVPXTTVPSE BPVPSE BTXSE BPVVE BPVVE BTSXSE BPTVPXTTTVVE BPVVE BTXSE BTXXVPSE BPTTTTTTTTVVE BTXSE BPVPSE BTXSE BPTVPSE BTXXTVPSE BPVVE BPVVE BPVVE BPTTVVE BPVVE BPVVE BTXXVVE BTXXVVE BTXXVPXVVE "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Wrong_StringGenrater"
      ],
      "metadata": {
        "id": "DNim0fuEiB2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#모든 가능한 알파벳들\n",
        "POSSIBLE_CHARS = \"BEPSTVX\"\n",
        "\n",
        "#잘못된 문자열 만들기\n",
        "def generate_corrupted_string(grammar, chars=POSSIBLE_CHARS):\n",
        "    #올바른 문자열에\n",
        "    good_string = generate_string(grammar)\n",
        "    index = np.random.randint(len(good_string))\n",
        "    good_char = good_string[index]\n",
        "    #있을수는 있지만 올바른 문자열엔 없는 문자열을\n",
        "    bad_char = np.random.choice(sorted(set(chars) - set(good_char)))\n",
        "    #중간에 하나 추가함\n",
        "    return good_string[:index] + bad_char + good_string[index + 1:]"
      ],
      "metadata": {
        "id": "zN88lc-qbMOH"
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#잘못된 문자열\n",
        "for _ in range(25):\n",
        "    print(generate_corrupted_string(embedded_reber_grammar), end=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QorG2sjibidd",
        "outputId": "0d1cdb30-d7f1-405d-8706-6fd0ac84fb85"
      },
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BTBPVVETV BTBTSSSPXXVVETE BTBTXXTTSTVPSETE BBBTXSETE BPBTPXSEPE BPBPVPXTTTTVPXTVPXVPXTTTVVEVE BTBXXXTVPSETE BEBTSSSSSXXVPXTVVETE BTBXTTVVETE BPBTXSTPE BTBTXXTTTVPSBTE BTBTXSETX BTBTSXSSTE BPBPVVEPT BTBPTVEETE BTBTSSXXTTVXETE BTBTSXTTVVETE BPBPVVTPE BTBTSXTTVVETE EPBPVPXVVEPE BPTTXSEPE BPBTXXSPXTVVEPE BTBTXSPTE BPTTSXXTVPXVVEPE PPBPVPSEPE "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Char_To_Int"
      ],
      "metadata": {
        "id": "XzIk9HnZiIEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#문자열을 숫자로 바꾸기, 문자의 인덱스 리스트로 변경한다.\n",
        "def strings_to_ids(s, chars=POSSIBLE_CHARS):\n",
        "    return [chars.index(c) for c in s]"
      ],
      "metadata": {
        "id": "PrErPKNRgirg"
      },
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DataGenerater"
      ],
      "metadata": {
        "id": "ZDBhm6oJiN6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#올바른 문자열, 잘못된 문자열 1 : 1 인 샘플과 레이블 생성\n",
        "def generate_dataset(size):\n",
        "    good_strings = [strings_to_ids(generate_string(embedded_reber_grammar)) for _ in range(size // 2)]\n",
        "    bad_strings = [strings_to_ids(generate_corrupted_string(embedded_reber_grammar)) for _ in range(size // 2)]\n",
        "    all_strings = good_strings + bad_strings\n",
        "    #ragged 텐서 생성\n",
        "    X = tf.ragged.constant(all_strings, ragged_rank=1)\n",
        "    y = np.array([[1.] for _ in range(len(good_strings))] + [[0.] for _ in range(len(bad_strings))])\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "wIQJCCtrb_6G"
      },
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate_Data"
      ],
      "metadata": {
        "id": "HXsHV0dPiUAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = generate_dataset(10000)\n",
        "X_valid, y_valid = generate_dataset(2000)\n",
        "X_test, y_test = generate_dataset(2000)"
      ],
      "metadata": {
        "id": "MrWpQwZecAGU"
      },
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])\n",
        "s = ''\n",
        "for i in X_train[0]:\n",
        "    s += POSSIBLE_CHARS[i]\n",
        "print(s, y_train[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTjH-aNsgYpK",
        "outputId": "6f485e1f-da47-486a-d072-60d824fd0d73"
      },
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 4 0 2 5 5 1 4 1], shape=(9,), dtype=int32)\n",
            "BTBPVVETE 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Binary_Sequence_Classifier"
      ],
      "metadata": {
        "id": "UYff-SVGiYoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 5\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    #인풋데이터는 ragged tensor, int32 타입\n",
        "    keras.layers.InputLayer(input_shape=[None], dtype=tf.int32, ragged=True),\n",
        "    keras.layers.Embedding(input_dim=len(POSSIBLE_CHARS), output_dim=embedding_size),\n",
        "    keras.layers.GRU(30),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "#네스테로프 가속 경사하강법 \n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.02, momentum=0.95, nesterov=True)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qfvhUibehqAf"
      },
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model_Train"
      ],
      "metadata": {
        "id": "XxCVuMK6kxut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-tLbiqajhY8",
        "outputId": "aa8ff22d-4e10-4207-ecfe-3e1b1168bae0"
      },
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_32/gru_1/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_32/gru_1/RaggedToTensor/boolean_mask/GatherV2:0\", shape=(None, 5), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_32/gru_1/RaggedToTensor/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 21s 61ms/step - loss: 0.6910 - accuracy: 0.5093 - val_loss: 0.6825 - val_accuracy: 0.5595\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 0.6678 - accuracy: 0.5720 - val_loss: 0.6706 - val_accuracy: 0.5975\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 0.6505 - accuracy: 0.5796 - val_loss: 0.6472 - val_accuracy: 0.6135\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 0.6356 - accuracy: 0.5963 - val_loss: 0.6239 - val_accuracy: 0.6290\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 19s 62ms/step - loss: 0.6059 - accuracy: 0.6342 - val_loss: 0.5778 - val_accuracy: 0.7010\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 0.5474 - accuracy: 0.7015 - val_loss: 0.5608 - val_accuracy: 0.5500\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 0.3996 - accuracy: 0.8227 - val_loss: 0.3930 - val_accuracy: 0.8175\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 0.2993 - accuracy: 0.8877 - val_loss: 0.3208 - val_accuracy: 0.8690\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 0.1955 - accuracy: 0.9362 - val_loss: 0.0895 - val_accuracy: 0.9820\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 19s 62ms/step - loss: 0.1733 - accuracy: 0.9435 - val_loss: 0.3036 - val_accuracy: 0.8240\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 0.1324 - accuracy: 0.9624 - val_loss: 0.0831 - val_accuracy: 0.9815\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 0.0776 - accuracy: 0.9827 - val_loss: 0.0692 - val_accuracy: 0.9840\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 0.0591 - accuracy: 0.9874 - val_loss: 0.0460 - val_accuracy: 0.9920\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 20s 62ms/step - loss: 0.0340 - accuracy: 0.9919 - val_loss: 0.0126 - val_accuracy: 0.9970\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 7.6187e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 6.7188e-04 - accuracy: 1.0000 - val_loss: 5.5484e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 19s 61ms/step - loss: 5.0684e-04 - accuracy: 1.0000 - val_loss: 4.3633e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 19s 62ms/step - loss: 4.1006e-04 - accuracy: 1.0000 - val_loss: 3.6166e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 19s 60ms/step - loss: 3.4005e-04 - accuracy: 1.0000 - val_loss: 3.0777e-04 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model_Evaluate"
      ],
      "metadata": {
        "id": "t--R2q2Skzwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpS4OKE8kp_I",
        "outputId": "6ea444ec-c471-4473-a6d5-66ae8be8f4c5"
      },
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1s 9ms/step - loss: 3.1642e-04 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.00031641536043025553, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 339
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9."
      ],
      "metadata": {
        "id": "akJLsnAjlwfR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9-1"
      ],
      "metadata": {
        "id": "1z0AbCO79i0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random_Date_Genrater"
      ],
      "metadata": {
        "id": "_6E6EwcLoalq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import date\n",
        "\n",
        "#January 22, 2019 -> 2019-01-22 형식으로\n",
        "MONTHS = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
        "\n",
        "def random_dates(n_dates):\n",
        "    min_date = date(1000, 1, 1).toordinal()\n",
        "    max_date = date(9999, 12, 31).toordinal()\n",
        "\n",
        "    #숫자\n",
        "    ordinals = np.random.randint(max_date - min_date, size=n_dates) + min_date\n",
        "    #month, day, year 을 빼내기위해서\n",
        "    dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
        "\n",
        "    #샘플\n",
        "    X = [MONTHS[dt.month - 1] + \" \" + dt.strftime(\"%d, %Y\") for dt in dates]\n",
        "    #타깃 YYYY-mm-dd 형식으로 변환\n",
        "    y = [dt.isoformat() for dt in dates]\n",
        "    \n",
        "    return X, y"
      ],
      "metadata": {
        "id": "v27muj8wkCaA"
      },
      "execution_count": 340,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_dates = 3\n",
        "x_example, y_example = random_dates(n_dates)\n",
        "print(\"{:25s}{:25s}\".format(\"Input\", \"Target\"))\n",
        "print(\"-\" * 50)\n",
        "for idx in range(n_dates):\n",
        "    print(\"{:25s}{:25s}\".format(x_example[idx], y_example[idx]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeR-1Hm5oFo_",
        "outputId": "e80b4a9f-86d2-40be-e8a2-196599cc3407"
      },
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input                    Target                   \n",
            "--------------------------------------------------\n",
            "July 22, 1344            1344-07-22               \n",
            "March 21, 7185           7185-03-21               \n",
            "January 02, 5192         5192-01-02               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#INPUT_OUTPUT_CHARS"
      ],
      "metadata": {
        "id": "AjkPHuAct72Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_CHARS = \"\".join(sorted(set(\"\".join(MONTHS) + \"0123456789, \")))\n",
        "OUTPUT_CHARS = \"0123456789-\"\n",
        "INPUT_CHARS, OUTPUT_CHARS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP1YNS6XoZZw",
        "outputId": "656257d8-27a8-4db4-8e52-7ada632a0038"
      },
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(' ,0123456789ADFJMNOSabceghilmnoprstuvy', '0123456789-')"
            ]
          },
          "metadata": {},
          "execution_count": 342
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Input_Output_Tokenizer"
      ],
      "metadata": {
        "id": "UEhYuB4duC1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_chars = MONTHS + ['0123456789, ']\n",
        "output_chars = ['0123456789-']\n",
        "\n",
        "input_tokenizer = keras.preprocessing.text.Tokenizer(lower=False, char_level=True)\n",
        "input_tokenizer.fit_on_texts(sorted(set(words)))\n",
        "input_vocab_size = len(input_tokenizer.word_index)\n",
        "\n",
        "output_tokenizer = keras.preprocessing.text.Tokenizer(lower=False, char_level=True)\n",
        "output_tokenizer.fit_on_texts(sorted(set(output_chars)))\n",
        "output_vocab_size = len(output_tokenizer.word_index)"
      ],
      "metadata": {
        "id": "OAsFfLXWo1Rp"
      },
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_tokenizer.word_index)\n",
        "print(output_tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KizIjzmbqf0Q",
        "outputId": "5578b3a6-3d86-4bc8-f3d5-4ec653ab8efe"
      },
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'e': 1, 'r': 2, 'u': 3, 'b': 4, 'a': 5, 'y': 6, 't': 7, 'c': 8, 'm': 9, 'J': 10, 'A': 11, 'p': 12, 'l': 13, 'n': 14, 'M': 15, 'o': 16, '0': 17, '1': 18, '2': 19, '3': 20, '4': 21, '5': 22, '6': 23, '7': 24, '8': 25, '9': 26, ',': 27, ' ': 28, 'i': 29, 'g': 30, 's': 31, 'D': 32, 'F': 33, 'h': 34, 'N': 35, 'v': 36, 'O': 37, 'S': 38}\n",
            "{'0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10, '-': 11}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = random_dates(3)\n",
        "\n",
        "print('-'*25)\n",
        "print(X[0])\n",
        "X = input_tokenizer.texts_to_sequences(X)\n",
        "print(X[0])\n",
        "X = input_tokenizer.sequences_to_texts(X)\n",
        "print(X[0][::2])\n",
        "\n",
        "print('-'*25)\n",
        "\n",
        "print(y[0])\n",
        "y = output_tokenizer.texts_to_sequences(y)\n",
        "print(y[0])\n",
        "y = output_tokenizer.sequences_to_texts(y)\n",
        "print(y[0][::2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGWcYoYYtO6s",
        "outputId": "f0dee642-7c7e-439c-a3e0-f01958b32332"
      },
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "April 09, 3947\n",
            "[11, 12, 2, 29, 13, 28, 17, 26, 27, 28, 20, 26, 21, 24]\n",
            "April 09, 3947\n",
            "-------------------------\n",
            "3947-04-09\n",
            "[4, 10, 5, 8, 11, 1, 5, 11, 1, 10]\n",
            "3947-04-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset_Generater"
      ],
      "metadata": {
        "id": "7RPhEGkzuG--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_date_strs(date_strs, tokenizer):\n",
        "    ids = [dt for dt in tokenizer.texts_to_sequences(date_strs)]\n",
        "    X = tf.ragged.constant(ids, ragged_rank=1)\n",
        "    return X.to_tensor() #ragged 텐서를 기본 텐서로 부족한 부분은 0 패딩토큰으로 채운다.\n",
        "\n",
        "def create_dataset(n_dates):\n",
        "    X, Y = random_dates(n_dates)\n",
        "    return prepare_date_strs(X, input_tokenizer), prepare_date_strs(Y, output_tokenizer)"
      ],
      "metadata": {
        "id": "mZ2Zw8YKp2gs"
      },
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, Y_train = create_dataset(10000)\n",
        "X_valid, Y_valid = create_dataset(2000)\n",
        "X_test, Y_test = create_dataset(2000)"
      ],
      "metadata": {
        "id": "jPvrYD8DtDxW"
      },
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0], Y_train[0], sep='\\n')\n",
        "print(input_tokenizer.sequences_to_texts([X_train[0].numpy()])[0][::2])\n",
        "print(output_tokenizer.sequences_to_texts([Y_train[0].numpy()])[0][::2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGavgDWOtExG",
        "outputId": "712cbee8-17b5-466f-9bfa-2b69258fa217"
      },
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([15  5  6 28 17 22 27 28 22 24 18 24  0  0  0  0  0  0], shape=(18,), dtype=int32)\n",
            "tf.Tensor([ 6  8  2  8 11  1  6 11  1  6], shape=(10,), dtype=int32)\n",
            "May 05, 5717\n",
            "5717-05-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Seq2Seq_Model"
      ],
      "metadata": {
        "id": "wdc1-KQzuLO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 32\n",
        "#출력 최대 길이 : 10 (yyyy-mm-dd)\n",
        "max_output_length = Y_train.shape[-1]\n",
        "\n",
        "#인코더 디코더 구조를 사용한다.\n",
        "\n",
        "#인코더, 시퀀스 투 벡터 구조\n",
        "encoder = keras.models.Sequential([\n",
        "    keras.layers.Embedding(input_dim=input_vocab_size + 1, output_dim=embedding_size, input_shape=[None]),\n",
        "    keras.layers.LSTM(128)\n",
        "])\n",
        "\n",
        "decoder = keras.models.Sequential([\n",
        "    keras.layers.LSTM(128, return_sequences=True),\n",
        "    keras.layers.Dense(output_vocab_size + 1, activation='softmax')\n",
        "])\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    encoder,\n",
        "    #출력길이가 10이니깐 인코더 출력을 10번 반복해서, 디코더가 10개의 출력을 만들도록함\n",
        "    keras.layers.RepeatVector(max_output_length),\n",
        "    decoder\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4u3NUSFrtE2-",
        "outputId": "2ca0f82b-ab1c-4e82-e66b-94dd302ab597"
      },
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_33 (Sequential)  (None, 128)               83680     \n",
            "                                                                 \n",
            " repeat_vector_10 (RepeatVec  (None, 10, 128)          0         \n",
            " tor)                                                            \n",
            "                                                                 \n",
            " sequential_34 (Sequential)  (None, 10, 12)            133132    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 216,812\n",
            "Trainable params: 216,812\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = keras.optimizers.Nadam()\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "yVNDBUquyezt"
      },
      "execution_count": 350,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aic4qNg5ysUY",
        "outputId": "fc5c8553-897c-46b2-eb7a-886cde347312"
      },
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 6s 11ms/step - loss: 1.8127 - accuracy: 0.3461 - val_loss: 1.4149 - val_accuracy: 0.4744\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.3985 - accuracy: 0.4978 - val_loss: 1.7827 - val_accuracy: 0.3640\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2699 - accuracy: 0.5557 - val_loss: 1.0006 - val_accuracy: 0.6413\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.8468 - accuracy: 0.6871 - val_loss: 0.7280 - val_accuracy: 0.7255\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6247 - accuracy: 0.7570 - val_loss: 0.5346 - val_accuracy: 0.7854\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.5561 - accuracy: 0.7894 - val_loss: 0.3968 - val_accuracy: 0.8443\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3240 - accuracy: 0.8756 - val_loss: 0.2627 - val_accuracy: 0.9046\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1886 - accuracy: 0.9446 - val_loss: 0.1323 - val_accuracy: 0.9689\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.5497 - accuracy: 0.8436 - val_loss: 0.2128 - val_accuracy: 0.9538\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1393 - accuracy: 0.9755 - val_loss: 0.0992 - val_accuracy: 0.9848\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0703 - accuracy: 0.9914 - val_loss: 0.0564 - val_accuracy: 0.9923\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0420 - accuracy: 0.9961 - val_loss: 0.0335 - val_accuracy: 0.9965\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0239 - accuracy: 0.9986 - val_loss: 0.0211 - val_accuracy: 0.9983\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0154 - accuracy: 0.9994 - val_loss: 0.0141 - val_accuracy: 0.9994\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0105 - accuracy: 0.9997 - val_loss: 0.0103 - val_accuracy: 0.9996\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0074 - accuracy: 0.9999 - val_loss: 0.0075 - val_accuracy: 0.9998\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9998\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 0.9998\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9998\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,Y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vDkzHXF4UDN",
        "outputId": "a4cea0ac-23ee-4b21-a254-41d2ca234535"
      },
      "execution_count": 352,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9999\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.002600297797471285, 0.9998999834060669]"
            ]
          },
          "metadata": {},
          "execution_count": 352
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model_Return_To_Strings"
      ],
      "metadata": {
        "id": "U-kh3b2j4wwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ids_to_strings(ids, tokenizer):\n",
        "    return tokenizer.sequences_to_texts(ids)\n",
        "\n",
        "print('-'*25)\n",
        "#X_new = X_test[:3]\n",
        "#패딩이 없는 데이터셋이라 잘 예측을 못함\n",
        "X_new = prepare_date_strs([\"May 02, 2020\", \"July 14, 1789\"], input_tokenizer)\n",
        "X_samples = ids_to_strings(X_new.numpy(), input_tokenizer)\n",
        "print(*[x_sample[::2] for x_sample in X_samples], sep='\\n')\n",
        "\n",
        "\n",
        "print('-'*25)\n",
        "Y_new = np.argmax(model.predict(X_new), axis=-1)\n",
        "Y_new = ids_to_strings(Y_new, output_tokenizer)\n",
        "print(*[y_sample[::2] for y_sample in Y_new], sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCAewYw44wTh",
        "outputId": "4f0ed7c5-1b17-4726-91f2-3c37d7d6bb74"
      },
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "May 02, 2020\n",
            "July 14, 1789\n",
            "-------------------------\n",
            "2020-02-02\n",
            "1789-09-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = X_train.shape[1]\n",
        "\n",
        "def prepare_date_strs_with_padded(date_strs, tokenizer):\n",
        "    X = prepare_date_strs(date_strs, tokenizer)\n",
        "    if X.shape[1] < max_input_length:\n",
        "        X = tf.pad(X, paddings=[[0,0], [0, max_input_length - X.shape[1]]])\n",
        "    return X\n",
        "\n",
        "\n",
        "print('-'*25)\n",
        "#패딩추가, 잘예측함\n",
        "X_new = prepare_date_strs_with_padded([\"May 02, 2020\", \"July 14, 1789\"], input_tokenizer)\n",
        "X_samples = ids_to_strings(X_new.numpy(), input_tokenizer)\n",
        "print(*[x_sample[::2] for x_sample in X_samples], sep='\\n')\n",
        "\n",
        "\n",
        "print('-'*25)\n",
        "Y_new = np.argmax(model.predict(X_new), axis=-1)\n",
        "Y_new = ids_to_strings(Y_new, output_tokenizer)\n",
        "print(*[y_sample[::2] for y_sample in Y_new], sep='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epYHWsGi79k0",
        "outputId": "2f2f334a-89ea-4e2b-afda-b58eef0d9b74"
      },
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------\n",
            "May 02, 2020\n",
            "July 14, 1789\n",
            "-------------------------\n",
            "2020-05-02\n",
            "1789-07-14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9-2"
      ],
      "metadata": {
        "id": "rVtUzeUm9l6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decoder_Input_Target_Shift"
      ],
      "metadata": {
        "id": "codkA4LE-68c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sos_id = output_vocab_size + 1\n",
        "\n",
        "def shifted_output_sequences(Y):\n",
        "    sos_tokens = tf.fill(dims=(len(Y), 1), value=sos_id)\n",
        "    return tf.concat([sos_tokens, Y[:, :-1]], axis=1)\n",
        "\n",
        "#타깃을 오른쪽으로 한번 shift 하고 맨앞에 sos 토큰을 추가한 디코더 입력\n",
        "#원래는 인코더벡터를 복사해서 디코더에 입력했지만, 쉬프트된 타깃을 주입해서 이전타깃이 무엇인지 확인할수 있게한다.\n",
        "X_train_decoder = shifted_output_sequences(Y_train)\n",
        "X_valid_decoder = shifted_output_sequences(Y_valid)\n",
        "X_test_decoder = shifted_output_sequences(Y_test)"
      ],
      "metadata": {
        "id": "A_4wMFqR9nVj"
      },
      "execution_count": 355,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids_to_strings(X_train_decoder[:5].numpy(), output_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX978r__-kld",
        "outputId": "92e05ad9-e094-4b28-9e38-e634a9fb9c0b"
      },
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['5 7 1 7 - 0 5 - 0',\n",
              " '3 7 6 2 - 0 6 - 1',\n",
              " '6 5 6 2 - 1 2 - 0',\n",
              " '3 9 8 7 - 0 3 - 0',\n",
              " '4 8 3 0 - 0 6 - 0']"
            ]
          },
          "metadata": {},
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "0hp8YMJC_BC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_embedding_size = 32\n",
        "decoder_embedding_size = 32\n",
        "\n",
        "lstm_units = 128\n",
        "\n",
        "encoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
        "encoder_embedding = keras.layers.Embedding(input_dim=input_vocab_size+1, output_dim=encoder_embedding_size)(encoder_input)\n",
        "#인코더의 출력벡터는 무시한다!!\n",
        "_, encoder_state_h, encoder_state_c = keras.layers.LSTM(lstm_units, return_state=True)(encoder_embedding)\n",
        "encoder_state = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "decoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
        "decoder_embedding = keras.layers.Embedding(output_vocab_size+1, decoder_embedding_size)(decoder_input)\n",
        "#대신 인코더의 LSTM의 상태와 디코더의 LSTM과 연결시킨다.\n",
        "decoder_lstm_output = keras.layers.LSTM(lstm_units, return_sequences=True)(decoder_embedding, initial_state=encoder_state)\n",
        "decoder_output = keras.layers.Dense(output_vocab_size+1, activation='softmax')(decoder_lstm_output)\n",
        "\n",
        "model = keras.models.Model(inputs=[encoder_input, decoder_input], outputs=[decoder_output])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7ZvSRmn-2XW",
        "outputId": "c6a51f1d-45a2-4a24-84ed-cbe47ca468c9"
      },
      "execution_count": 357,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_19 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_20 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_30 (Embedding)       (None, None, 32)     1248        ['input_19[0][0]']               \n",
            "                                                                                                  \n",
            " embedding_31 (Embedding)       (None, None, 32)     384         ['input_20[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_40 (LSTM)                 [(None, 128),        82432       ['embedding_30[0][0]']           \n",
            "                                 (None, 128),                                                     \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " lstm_41 (LSTM)                 (None, None, 128)    82432       ['embedding_31[0][0]',           \n",
            "                                                                  'lstm_40[0][1]',                \n",
            "                                                                  'lstm_40[0][2]']                \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, None, 12)     1548        ['lstm_41[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 168,044\n",
            "Trainable params: 168,044\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([X_train, X_train_decoder], Y_train, epochs=10, validation_data=([X_valid, X_valid_decoder], Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_HI_KKmAwLO",
        "outputId": "72ae90e5-0506-436c-af1d-44551c55376c"
      },
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 7s 11ms/step - loss: 1.6702 - accuracy: 0.3712 - val_loss: 1.4184 - val_accuracy: 0.4505\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.2271 - accuracy: 0.5284 - val_loss: 0.9708 - val_accuracy: 0.6352\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.6705 - accuracy: 0.7629 - val_loss: 0.3728 - val_accuracy: 0.8963\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2285 - accuracy: 0.9464 - val_loss: 0.1230 - val_accuracy: 0.9808\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0939 - accuracy: 0.9863 - val_loss: 0.0562 - val_accuracy: 0.9954\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0329 - accuracy: 0.9991 - val_loss: 0.0236 - val_accuracy: 0.9997\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0376 - accuracy: 0.9948 - val_loss: 0.0176 - val_accuracy: 0.9998\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9999\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ids_to_strings(np.argmax(model.predict([X_train[:5], X_train_decoder[:5]]), axis=-1), output_tokenizer))\n",
        "print(ids_to_strings(Y_train[:5].numpy(), output_tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxR3yt-2HEWs",
        "outputId": "3b76fbed-083d-4bd5-f4ce-2b221bcfa694"
      },
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['5 7 1 7 - 0 5 - 0 5', '3 7 6 2 - 0 6 - 1 3', '6 5 6 2 - 1 2 - 0 1', '3 9 8 7 - 0 3 - 0 4', '4 8 3 0 - 0 6 - 0 5']\n",
            "['5 7 1 7 - 0 5 - 0 5', '3 7 6 2 - 0 6 - 1 3', '6 5 6 2 - 1 2 - 0 1', '3 9 8 7 - 0 3 - 0 4', '4 8 3 0 - 0 6 - 0 5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X_new = output_tokenizer.texts_to_sequences([\"1789-07-14\", \"2020-05-01\"])\n",
        "\n",
        "def predict_date_strs(date_strs):\n",
        "    X = prepare_date_strs_with_padded(date_strs, input_tokenizer)\n",
        "    #X = date_strs\n",
        "    sos_id = output_vocab_size + 1\n",
        "    Y_pred = tf.fill(dims=(len(X), 1), value=sos_id)\n",
        "\n",
        "    for index in range(max_output_length):\n",
        "        X_decoder = tf.pad(Y_pred, [[0, 0], [0, max_output_length-index]])\n",
        "        Y_probas = tf.argmax(model.predict([X, X_decoder]), axis=-1, output_type=tf.int32)\n",
        "        Y_pred = tf.concat([Y_pred, Y_probas[:, index:index+1]], axis=1)\n",
        "    return ids_to_strings(Y_pred.numpy(), output_tokenizer)\n",
        "\n",
        "print(predict_date_strs([\"May 02, 2020\", \"July 14, 1789\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql1g0m9DHtk0",
        "outputId": "1936cdca-74b5-4e0f-cf06-9fde2fb53d37"
      },
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2 0 2 0 - 0 5 - 0 2', '1 7 8 9 - 0 7 - 1 4']\n"
          ]
        }
      ]
    }
  ]
}