{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KFood_Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18hwDSA1spYJuwYFlfluXut0WoHKVRv3n",
      "authorship_tag": "ABX9TyM5ja8pDAZ3kTEaBd20dHie",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimhwijin/HandsOnMachineLearing/blob/main/KFood_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g2bP4EwVSFPO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import os\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import csv\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = (299, 299)\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "xCxt-16DSKXv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋\n",
        "DATASET_NAME = 'kfood'\n",
        "DRIVE_PATH = '/content/drive/MyDrive/Datasets'\n",
        "\n",
        "DATASET_PATH = DRIVE_PATH + \"/\" + DATASET_NAME\n",
        "filepath = DATASET_PATH\n",
        "print(os.path.exists(filepath))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFPieOtJSLTv",
        "outputId": "583d22c0-8623-4179-fe1f-e60175bdf1d5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#class_label 매칭 딕셔너리로 저장\n",
        "labels = None\n",
        "classes = None\n",
        "with open(os.path.join(filepath, 'class_label.csv'),'r') as f:\n",
        "    w = csv.reader(f)\n",
        "    classes = w.__next__()\n",
        "    labels = w.__next__()\n",
        "#print(len(classes), len(labels), classes, labels)\n",
        "label_to_class = [0]*len(labels)\n",
        "for _class, _label in zip(classes, labels):\n",
        "    label_to_class[int(_label)] = _class.encode('utf-8')\n",
        "\n",
        "class_to_label = {_class: _label for _label, _class in enumerate(label_to_class)}\n",
        "\n",
        "tf_class_to_label = tf.constant(list(class_to_label.keys()))\n"
      ],
      "metadata": {
        "id": "Z2hYKvEfSMmv"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_paths = sorted(glob(os.path.join(filepath, '*', '*')))\n",
        "class_names = [class_path.split('/')[-1] for class_path in class_paths]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "JODZnXrj5G75",
        "outputId": "f5bc4692-4046-4630-9f9d-659c9c116fed"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-14968f28d188>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclass_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclass_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclass_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_paths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclass_to_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: '갈비구이'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_paths = sorted(glob(os.path.join(filepath, '*', '*')))\n",
        "label_paths = [label_path.split('/')[-1] for label_path in label_paths if os.path.isdir(label_path)]\n",
        "label_paths[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LV3Ksi4N6ERw",
        "outputId": "3ac116ae-f59b-4ef2-9490-47403d8da2aa"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'갈비구이'"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(filepath, 'class_label.csv'),'w', encoding='utf-8') as f:\n",
        "    w = csv.writer(f) \n",
        "    w.writerow(list(range(len(label_paths))))\n",
        "    w.writerow(label_paths)"
      ],
      "metadata": {
        "id": "n_dwDlbe6129"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(filepath, 'class_label.csv'),'r') as f:\n",
        "    w = csv.reader(f)\n",
        "    classes = w.__next__()\n",
        "    labels = w.__next__()\n",
        "\n",
        "print(labels)\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEHxR8dM7kXz",
        "outputId": "1e6a724d-d82f-4675-f124-233af2d8643d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['갈비구이', '갈치구이', '고등어구이', '곱창구이', '닭갈비', '더덕구이', '떡갈비', '불고기', '삼겹살', '장어구이', '조개구이', '조기구이', '황태구이', '훈제오리', '계란국', '떡국_만두국', '무국', '미역국', '북엇국', '시래기국', '육개장', '콩나물국', '과메기', '양념치킨', '젓갈', '콩자반', '편육', '피자', '후라이드치킨', '갓김치', '깍두기', '나박김치', '무생채', '배추김치', '백김치', '부추김치', '열무김치', '오이소박이', '총각김치', '파김치', '가지볶음', '고사리나물', '미역줄기볶음', '숙주나물', '시금치나물', '애호박볶음', '경단', '꿀떡', '송편', '만두', '라면', '막국수', '물냉면', '비빔냉면', '수제비', '열무국수', '잔치국수', '짜장면', '짬뽕', '쫄면', '칼국수', '콩국수', '꽈리고추무침', '도라지무침', '도토리묵', '잡채', '콩나물무침', '홍어무침', '회무침', '김밥', '김치볶음밥', '누룽지', '비빔밥', '새우볶음밥', '알밥', '유부초밥', '잡곡밥', '주먹밥', '감자채볶음', '건새우볶음', '고추장진미채볶음', '두부김치', '떡볶이', '라볶이', '멸치볶음', '소세지볶음', '어묵볶음', '오징어채볶음', '제육볶음', '주꾸미볶음', '보쌈', '수정과', '식혜', '간장게장', '양념게장', '깻잎장아찌', '떡꼬치', '감자전', '계란말이', '계란후라이', '김치전', '동그랑땡', '생선전', '파전', '호박전', '곱창전골', '갈치조림', '감자조림', '고등어조림', '꽁치조림', '두부조림', '땅콩조림', '메추리알장조림', '연근조림', '우엉조림', '장조림', '코다리조림', '전복죽', '호박죽', '김치찌개', '닭계장', '동태찌개', '된장찌개', '순두부찌개', '갈비찜', '계란찜', '김치찜', '꼬막찜', '닭볶음탕', '수육', '순대', '족발', '찜닭', '해물찜', '갈비탕', '감자탕', '곰탕_설렁탕', '매운탕', '삼계탕', '추어탕', '고추튀김', '새우튀김', '오징어튀김', '약과', '약식', '한과', '멍게', '산낙지', '물회', '육회']\n",
            "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_crop_points(filepath):\n",
        "    crops = {}\n",
        "    properties = os.path.join(filepath, \"crop_area.properties\")\n",
        "    with open(properties, 'r') as p:\n",
        "        for row in p:\n",
        "            name, crop = row.replace(\"\\n\", \"\").replace(\" \", \"\").split(\"=\")\n",
        "            if name != \"\" and crop != \"\":\n",
        "                #name = name.encode('utf-8')\n",
        "                crop = crop.split(\",\")\n",
        "                if len(crop) >= 4:\n",
        "                    crop = [int(crop[1]), int(crop[0]), int(crop[3]), int(crop[2])]\n",
        "                    crops[name] = crop\n",
        "                elif len(crop) == 2:\n",
        "                    crop = [0, 0, int(crop[1]), int(crop[0])]\n",
        "                    crops[name] = crop\n",
        "            \n",
        "    return crops"
      ],
      "metadata": {
        "id": "HGO2RC4dSN7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#crop 지점 정보 빼오기\n",
        "crop_points = {}\n",
        "class_list = list(glob( os.path.join(filepath, \"*\", \"*\")))\n",
        "class_list = [class_name for class_name in class_list if os.path.isdir(class_name)]\n",
        "for class_name in class_list:\n",
        "    crop_points.update(get_image_crop_points(class_name))\n",
        "\n",
        "tf_crop_image_names = tf.constant(list(crop_points.keys()), dtype=tf.string)\n",
        "tf_crop_points = tf.constant(list(crop_points.values()))\n"
      ],
      "metadata": {
        "id": "9QZ_wNXySc6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋의 이미지 경로 및 레이블 저장\n",
        "image_paths = sorted(glob(os.path.join(filepath, \"*\", \"*\", \"*\")))\n",
        "#image_paths = sorted(list(DATASET_PATH.glob('*/*/*')))\n",
        "image_paths = [image_path for image_path in image_paths if image_path.split('/')[-1].split('.')[-1].lower() in (\"png\", \"jpg\", \"jpeg\")]\n",
        "#labels = [class_to_label[Path(image_path).parent.stem] for image_path in image_paths]\n",
        "print(len(image_paths))#, len(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAQPUtWjSdcu",
        "outputId": "06a85bc6-5d5b-45dd-e936-613c34a6ed77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#filepath = tf.compat.path_to_str(image_paths[0])\n",
        "filepath = image_paths[0]\n",
        "tf.strings.lower(tf.strings.split(filepath, \".\")[-1])\n",
        "tf.strings.split(tf.strings.split(filepath, \"/\")[-1], \".\")[0]\n",
        "tf.strings.split(filepath, \"/\")[-2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNaA3853Cn37",
        "outputId": "d9ba3366-bf82-4c3b-c39c-3e319e9b095b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe1\\x84\\x80\\xe1\\x85\\xa1\\xe1\\x86\\xaf\\xe1\\x84\\x87\\xe1\\x85\\xb5\\xe1\\x84\\x80\\xe1\\x85\\xae\\xe1\\x84\\x8b\\xe1\\x85\\xb5'>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_and_crop_image_add_label(tf_filepath):\n",
        "    \n",
        "    image = tf.io.read_file(tf_filepath) # 이미지 파일 읽기\n",
        "    filepath = tf_filepath\n",
        "    #format decoding\n",
        "    image_format = tf.strings.lower(tf.strings.split(filepath, \".\")[-1])\n",
        "\n",
        "    if image_format == \"jpeg\":\n",
        "        image = tf.image.decode_jpeg(image) # JPEG-encoded -> uint8 tensor (RGB format)\n",
        "    elif image_format == \"png\":\n",
        "        image = tf.image.decode_png(image, channels=3, dtype=tf.uint8)\n",
        "\n",
        "    else:\n",
        "        image = tf.image.decode_image(image, channels=3, expand_animations=False)\n",
        "    \n",
        "\n",
        "\n",
        "    #crop\n",
        "    image_name = tf.strings.split(tf.strings.split(filepath, \"/\")[-1], \".\")[0]\n",
        "    tf_image_idx = tf.where(tf_crop_image_names == image_name)\n",
        "    \n",
        "    #crop 정보가 있으면 크롭\n",
        "    if tf.reduce_all(tf.not_equal(tf.shape(tf_image_idx), tf.constant((0, 1), dtype=tf.int32))):\n",
        "        crop_offsets = tf_crop_points[tf.reshape(tf_image_idx, shape=())]\n",
        "        image = tf.image.crop_to_bounding_box(image, crop_offsets[0], crop_offsets[1], crop_offsets[2], crop_offsets[3])\n",
        "    \n",
        "    #labeling\n",
        "    class_name = tf.strings.split(filepath, \"/\")[-2]\n",
        "    tf_class_name_idx = tf.where(tf_class_to_label == class_name)\n",
        "    \n",
        "    try:\n",
        "        label = tf.reshape(tf_class_name_idx, shape=())\n",
        "    except:\n",
        "        label = 0\n",
        "        print(\"label error\")\n",
        "\n",
        "    return image, int(label)"
      ],
      "metadata": {
        "id": "8pySZCKLSfG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def central_crop(image):\n",
        "    shape = tf.shape(image)\n",
        "    min_dim = tf.reduce_min([shape[0], shape[1]])\n",
        "    top_crop = (shape[0] - min_dim) // 2\n",
        "    bottom_crop = shape[0] - top_crop\n",
        "    left_crop = (shape[1] - min_dim) // 2\n",
        "    right_crop = shape[1] - left_crop\n",
        "    return image[top_crop : bottom_crop, left_crop : right_crop]\n",
        "\n",
        "\n",
        "def resizing_image(image, label):\n",
        "    image = central_crop(image)\n",
        "    image = tf.image.resize(image, [299, 299], method=\"nearest\")\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "9b7cQHj-SgF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_kfood_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None, n_parse_threads=5, batch_size=32, cache=False):\n",
        "\n",
        "    filenames_dataset = tf.data.Dataset.from_tensor_slices(filepaths)\n",
        "    dataset = filenames_dataset.map(parse_and_crop_image_add_label, num_parallel_calls=n_parse_threads)\n",
        "    dataset = dataset.map(resizing_image, num_parallel_calls=n_parse_threads)\n",
        "    \n",
        "    if cache:\n",
        "        dataset = dataset.cache()\n",
        "    if shuffle_buffer_size:\n",
        "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
        "    if batch_size:\n",
        "        dataset = dataset.batch(batch_size)\n",
        "    return dataset.prefetch(1)"
      ],
      "metadata": {
        "id": "jfTqbrvFSgbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋 생성\n",
        "dataset = make_kfood_dataset(image_paths, shuffle_buffer_size=10000, n_parse_threads=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "pEuxjK5uSheK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in dataset.take(1):\n",
        "    print(x)"
      ],
      "metadata": {
        "id": "5L90Caq5XHQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_image_plot_4():\n",
        "    for images, labels in dataset.take(1):\n",
        "        plt.figure(figsize=(16,8))\n",
        "        plt.axis(\"off\")\n",
        "        for i in range(4):\n",
        "            plt.subplot(1, 4, i+1)\n",
        "            image = tf.cast(images[i], dtype=tf.float32)\n",
        "            plt.imshow(image / 255.)\n",
        "            print(bytes(tf_class_to_label[int(labels[i])].numpy()).decode('utf-8'))\n",
        "            \n",
        "dataset_image_plot_4()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "6qd2b1bTSjdf",
        "outputId": "71b8e8dd-167a-4965-fc13-1d79b0de19d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-e4918d4e4f40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_class_to_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdataset_image_plot_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-e4918d4e4f40>\u001b[0m in \u001b[0;36mdataset_image_plot_4\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdataset_image_plot_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    798\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    784\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   2843\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2844\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2845\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2846\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2847\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7106\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7107\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 0 values, but the requested shape has 1\n\t [[{{node ArithmeticOptimizer/ReorderCastLikeAndValuePreserving_int32_Reshape}}]] [Op:IteratorGetNext]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import os\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import csv\n",
        "\n",
        "IMAGE_SIZE = (299, 299)\n",
        "BATCH_SIZE = 32\n",
        "#데이터셋\n",
        "DATASET_NAME = 'kfood'\n",
        "#DRIVE_PATH = Path(os.getcwd())\n",
        "DATASET_PATH = DRIVE_PATH / DATASET_NAME\n",
        "filepath = DATASET_PATH\n",
        "print(filepath.exists())\n",
        "\n",
        "#class_label 매칭 딕셔너리로 저장\n",
        "labels = None\n",
        "classes = None\n",
        "with open(filepath / 'class_label.csv','r') as f:\n",
        "    w = csv.reader(f)\n",
        "    classes = w.__next__()\n",
        "    labels = w.__next__()\n",
        "#print(len(classes), len(labels), classes, labels)\n",
        "class_to_label = {}\n",
        "for _class, _label in zip(classes, labels):\n",
        "    class_to_label[_class] = int(_label)\n",
        "\n",
        "tf_class_to_label = list(class_to_label.keys())\n",
        "tf_class_to_label = [utf_8.encode(\"utf-8\") for utf_8 in tf_class_to_label]\n",
        "tf_class_to_label = tf.constant(tf_class_to_label)\n",
        "\n",
        "\n",
        "def get_image_crop_points(filepath):\n",
        "    crops = {}\n",
        "    properties = filepath / \"crop_area.properties\"\n",
        "    with open(properties, 'r') as p:\n",
        "        for row in p:\n",
        "            name, crop = row.replace(\"\\n\", \"\").replace(\" \", \"\").split(\"=\")\n",
        "            if name != \"\" and crop != \"\":\n",
        "                #name = name.encode('utf-8')\n",
        "                crop = crop.split(\",\")\n",
        "                if len(crop) >= 4:\n",
        "                    crop = [int(crop[1]), int(crop[0]), int(crop[3]), int(crop[2])]\n",
        "                    crops[name] = crop\n",
        "                elif len(crop) == 2:\n",
        "                    crop = [0, 0, int(crop[1]), int(crop[0])]\n",
        "                    crops[name] = crop\n",
        "            \n",
        "    return crops\n",
        "\n",
        "#crop 지점 정보 빼오기\n",
        "crop_points = {}\n",
        "class_list = list(filepath.glob(\"*/*\"))\n",
        "class_list = [class_name for class_name in class_list if class_name.is_dir()]\n",
        "for class_name in class_list:\n",
        "    crop_points.update(get_image_crop_points(class_name))\n",
        "\n",
        "tf_crop_image_names = tf.constant(list(crop_points.keys()), dtype=tf.string)\n",
        "tf_crop_points = tf.constant(list(crop_points.values()))\n",
        "\n",
        "#데이터셋의 이미지 경로 및 레이블 저장\n",
        "from glob import glob\n",
        "image_paths = sorted(glob(str(DATASET_PATH) + \"/*/*/*\"))\n",
        "image_paths = [image_path for image_path in image_paths if image_path.split(\"/\")[-1].split(\".\")[-1].lower() in (\"png\", \"jpg\", \"jpeg\")]\n",
        "#labels = [class_to_label[Path(image_path).parent.stem] for image_path in image_paths]\n",
        "print(len(image_paths))#, len(labels))\n",
        "\n",
        "\n",
        "def parse_and_crop_image_add_label(tf_filepath):\n",
        "    \n",
        "    image = tf.io.read_file(tf_filepath) # 이미지 파일 읽기\n",
        "    filepath = tf.compat.path_to_str(tf_filepath)\n",
        "    #format decoding\n",
        "    image_format = tf.strings.lower(tf.strings.split(filepath, \".\")[-1])\n",
        "\n",
        "    if image_format == \"jpeg\":\n",
        "        image = tf.image.decode_jpeg(image, channels=3) # JPEG-encoded -> uint8 tensor (RGB format)\n",
        "    elif image_format == \"png\":\n",
        "        image = tf.image.decode_png(image, channels=3, dtype=tf.uint8)\n",
        "    else:    \n",
        "        image = tf.image.decode_image(image, channels=3, expand_animations=False)\n",
        "\n",
        "\n",
        "    #crop\n",
        "    image_name = tf.strings.split(tf.strings.split(filepath, \"/\")[-1], \".\")[0]\n",
        "    tf_image_idx = tf.where(tf_crop_image_names == image_name)\n",
        "    \n",
        "    #crop 정보가 있으면 크롭\n",
        "    if tf.reduce_all(tf.not_equal(tf.shape(tf_image_idx), tf.constant((0, 1), dtype=tf.int32))):\n",
        "        crop_offsets = tf_crop_points[tf.reshape(tf_image_idx, shape=())]\n",
        "        image = tf.image.crop_to_bounding_box(image, crop_offsets[0], crop_offsets[1], crop_offsets[2], crop_offsets[3])\n",
        "    \n",
        "    #labeling\n",
        "    class_name = tf.strings.split(filepath, \"/\")[-2]\n",
        "    tf_class_name_idx = tf.where(tf_class_to_label == class_name)\n",
        "\n",
        "    tf.print(tf_class_name_idx)\n",
        "    \n",
        "    try:\n",
        "        label = tf.reshape(tf_class_name_idx, shape=())\n",
        "    except:\n",
        "        label = 0\n",
        "        tf.print(\"label error\")\n",
        "\n",
        "    return image, int(label)\n",
        "\n",
        "def central_crop(image):\n",
        "    shape = tf.shape(image)\n",
        "    min_dim = tf.reduce_min([shape[0], shape[1]])\n",
        "    top_crop = (shape[0] - min_dim) // 2\n",
        "    bottom_crop = shape[0] - top_crop\n",
        "    left_crop = (shape[1] - min_dim) // 2\n",
        "    right_crop = shape[1] - left_crop\n",
        "    return image[top_crop : bottom_crop, left_crop : right_crop]\n",
        "\n",
        "\n",
        "def resizing_image(image, label):\n",
        "    image = central_crop(image)\n",
        "    image = tf.image.resize(image, [299, 299], method=\"nearest\")\n",
        "    return image, label\n",
        "\n",
        "def make_kfood_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None, n_parse_threads=5, batch_size=32, cache=False):\n",
        "\n",
        "    filenames_dataset = tf.data.Dataset.from_tensor_slices(filepaths)\n",
        "    dataset = filenames_dataset.map(parse_and_crop_image_add_label, num_parallel_calls=n_parse_threads)\n",
        "    dataset = dataset.map(resizing_image, num_parallel_calls=n_parse_threads)\n",
        "    #dataset = filenames_dataset.map(spa)\n",
        "    if cache:\n",
        "        dataset = dataset.cache()\n",
        "    if shuffle_buffer_size:\n",
        "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
        "    if batch_size:\n",
        "        dataset = dataset.batch(batch_size)\n",
        "    return dataset.prefetch(1)\n",
        "\n",
        "\n",
        "#데이터셋 생성\n",
        "dataset = make_kfood_dataset(image_paths, shuffle_buffer_size=10000, n_parse_threads=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "1m3q1BRSXuI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_class_to_label\n",
        "print(tf.strings.unicode_decode(tf.strings.split(image_paths[0], '/')[-2], input_encoding='UTF-8'))\n",
        "text_ = tf.constant('갈비구이')\n",
        "text_chars = tf.strings.unicode_decode(text_, input_encoding='UTF-8')\n",
        "text_utf8 = tf.strings.unicode_encode(text_chars, output_encoding='UTF-8')\n",
        "print(tf.strings.split(image_paths[0], '/'))\n",
        "print(text_chars)\n",
        "print(image_paths[0])\n",
        "#print(text_utf8)\n",
        "#print(bytes(tf.strings.split(image_paths[0], '/')[-2].numpy()).decode('utf-8'))"
      ],
      "metadata": {
        "id": "WsDWK5f5gZoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(b'\\xe1\\x84\\x80\\xe1\\x85\\xa1\\xe1\\x86\\xaf\\xe1\\x84\\x87\\xe1\\x85\\xb5\\xe1\\x84\\x80\\xe1\\x85\\xae\\xe1\\x84\\x8b\\xe1\\x85\\xb5'.decode('utf-8').encode('utf-8'))\n"
      ],
      "metadata": {
        "id": "EsqcPP5BkQDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_paths[0].split('/')[-2].encode('utf-8'))\n",
        "image_names = [image_path.split('/')[-2] for image_path in image_paths]"
      ],
      "metadata": {
        "id": "cDfuY1mglfVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_names[0].encode('utf-8'))"
      ],
      "metadata": {
        "id": "JolKbU1AmuCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_image_plot_4():\n",
        "    for images, labels in dataset.take(1):\n",
        "        plt.figure(figsize=(16,8))\n",
        "        plt.axis(\"off\")\n",
        "        for i in range(4):\n",
        "            plt.subplot(1, 4, i+1)\n",
        "            image = tf.cast(images[i], dtype=tf.float32)\n",
        "            plt.imshow(image / 255.)\n",
        "            print(bytes(tf_class_to_label[int(labels[i])].numpy()).decode('utf-8'))\n",
        "            \n",
        "dataset_image_plot_4()"
      ],
      "metadata": {
        "id": "9ic690RPYlBS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}