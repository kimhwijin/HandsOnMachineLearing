{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_API_13.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPd94hNZov+OrUlwnYrRRiG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimhwijin/HandsOnMachineLearing/blob/main/Data_API_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmZgahlPGeSq"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouEu_zE8o6Yt"
      },
      "source": [
        "# 데이터셋 API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuLitTzzZYTO",
        "outputId": "881d7434-d184-40cf-edd1-7667f55e86b0"
      },
      "source": [
        "X = tf.range(10)\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
        "#dataset = tf.data.Dataset.range(10)\n",
        "print(X, dataset)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32) <TensorSliceDataset shapes: (), types: tf.int32>\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(5, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(7, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(9, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y0vq127Z0Gb",
        "outputId": "df82d99b-5b4f-4f06-de0f-726da9c580e3"
      },
      "source": [
        "#연쇄 변환\n",
        "dataset = dataset.repeat(3).batch(7)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
            "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
            "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FziT0xsMZfBk",
        "outputId": "c8ed2df7-08cf-49c0-884e-96fd5aa1dcfc"
      },
      "source": [
        "#데이터셋 할당받지않으면 데이터가 다 날라감\n",
        "dataset.repeat(3).batch(7)\n",
        "print(dataset)\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X).repeat(3).batch(7)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<BatchDataset shapes: (None,), types: tf.int32>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60Txpfoqj09q",
        "outputId": "e3bce43e-cfc4-44db-b3ae-e0663eff4dd0"
      },
      "source": [
        "dataset = dataset.map(lambda x: x * 2)\n",
        "for item in dataset:\n",
        "    print(item)\n",
        "\n",
        "dataset = dataset.unbatch()\n",
        "dataset = dataset.filter(lambda x: x < 10)\n",
        "\n",
        "for item in dataset.take(3):\n",
        "    print(item)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
            "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
            "tf.Tensor([16 18], shape=(2,), dtype=int32)\n",
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nl9nt52kJVW",
        "outputId": "7ec9e91f-e29b-4b43-fc87-7e18beecb4a6"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "dataset = tf.data.Dataset.range(10).repeat(3)\n",
        "dataset = dataset.shuffle(buffer_size=3, seed=42).batch(7)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 3 0 4 2 5 6], shape=(7,), dtype=int64)\n",
            "tf.Tensor([8 7 1 0 3 2 5], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 6 9 8 9 7 0], shape=(7,), dtype=int64)\n",
            "tf.Tensor([3 1 4 5 2 8 7], shape=(7,), dtype=int64)\n",
            "tf.Tensor([6 9], shape=(2,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Owsygejxlx7i",
        "outputId": "98fa992b-45cd-4a78-dbc5-80bedb9f2962"
      },
      "source": [
        "#셔플 후 반복\n",
        "dataset = tf.data.Dataset.range(10).shuffle(buffer_size=3)\n",
        "for item in dataset:\n",
        "    print(item)\n",
        "print(\"---\")\n",
        "dataset = dataset.repeat(3)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(6, shape=(), dtype=int64)\n",
            "tf.Tensor(5, shape=(), dtype=int64)\n",
            "tf.Tensor(7, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(8, shape=(), dtype=int64)\n",
            "tf.Tensor(9, shape=(), dtype=int64)\n",
            "---\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(5, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(8, shape=(), dtype=int64)\n",
            "tf.Tensor(9, shape=(), dtype=int64)\n",
            "tf.Tensor(7, shape=(), dtype=int64)\n",
            "tf.Tensor(6, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(5, shape=(), dtype=int64)\n",
            "tf.Tensor(6, shape=(), dtype=int64)\n",
            "tf.Tensor(7, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(8, shape=(), dtype=int64)\n",
            "tf.Tensor(9, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(4, shape=(), dtype=int64)\n",
            "tf.Tensor(3, shape=(), dtype=int64)\n",
            "tf.Tensor(6, shape=(), dtype=int64)\n",
            "tf.Tensor(7, shape=(), dtype=int64)\n",
            "tf.Tensor(5, shape=(), dtype=int64)\n",
            "tf.Tensor(2, shape=(), dtype=int64)\n",
            "tf.Tensor(8, shape=(), dtype=int64)\n",
            "tf.Tensor(9, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jsxo83zo_KB"
      },
      "source": [
        "# Split_Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS7BMhn3ox4x"
      },
      "source": [
        "#데이터셋을 여러파일로 나누기\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#데이터셋 불러오기\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "#정규화\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_mean = scaler.mean_\n",
        "X_std = scaler.scale_"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9JAhvvTlyPF"
      },
      "source": [
        "#\n",
        "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
        "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
        "    os.makedirs(housing_dir, exist_ok=True)\n",
        "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
        "\n",
        "    filepaths = []\n",
        "    #데이터 개수를, 파일 개수로 split\n",
        "    m = len(data)\n",
        "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
        "        part_csv = path_format.format(name_prefix, file_idx)\n",
        "        filepaths.append(part_csv)\n",
        "        #파일생성\n",
        "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
        "            #헤더 작성\n",
        "            if header is not None:\n",
        "                f.write(header)\n",
        "                f.write(\"\\n\")\n",
        "            #데이터 작성\n",
        "            for row_idx in row_indices:\n",
        "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
        "                f.write(\"\\n\")\n",
        "    return filepaths\n",
        "\n",
        "train_data = np.c_[X_train, y_train]\n",
        "valid_data = np.c_[X_valid, y_valid]\n",
        "test_data = np.c_[X_test, y_test]\n",
        "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
        "header = \",\".join(header_cols)\n",
        "\n",
        "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
        "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
        "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_Phc7TnsZY0",
        "outputId": "fc1e75da-f4d1-44d4-e7e8-f97bbc946bd1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(pd.read_csv(train_filepaths[0]).head())\n",
        "\n",
        "with open(train_filepaths[0]) as f:\n",
        "    for i in range(5):\n",
        "        print(f.readline(), end=\"\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   MedInc  HouseAge  AveRooms  ...  Latitude  Longitude  MedianHouseValue\n",
            "0  3.5214      15.0  3.049945  ...     37.63    -122.43             1.442\n",
            "1  5.3275       5.0  6.490060  ...     33.69    -117.39             1.687\n",
            "2  3.1000      29.0  7.542373  ...     38.44    -122.98             1.621\n",
            "3  7.1736      12.0  6.289003  ...     33.55    -117.70             2.621\n",
            "4  2.0549      13.0  5.312457  ...     33.93    -116.93             0.956\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n",
            "3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442\n",
            "5.3275,5.0,6.490059642147117,0.9910536779324056,3464.0,3.4433399602385686,33.69,-117.39,1.687\n",
            "3.1,29.0,7.5423728813559325,1.5915254237288134,1328.0,2.2508474576271187,38.44,-122.98,1.621\n",
            "7.1736,12.0,6.289002557544757,0.9974424552429667,1054.0,2.6956521739130435,33.55,-117.7,2.621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj0inFV6uLCk"
      },
      "source": [
        "#파일 경로에서 데이터셋 생성하기\n",
        "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)\n",
        "\n",
        "#한번에 5개 데이터를 읽는 데이터셋, 맨처음 줄은 열이기 때문에 스킵한다.\n",
        "n_readers = 5\n",
        "dataset = filepath_dataset.interleave(\n",
        "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "    cycle_length=n_readers)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}